{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Cog Sci abstract data\n",
    "March 4, 2018\n",
    "\n",
    "This notebook grabs the cogsci proceedings data and does the following.\n",
    "\n",
    "###### LSA:\n",
    "- pre-processing: creates tf-idf representation of each abstract.\n",
    "- analysis: performs Latent Semantic Analysis (truncated SVD) using gensim for latent space document and term representation.\n",
    "\n",
    "###### word2vec:\n",
    "- skip-gram/cbow pre-processing\n",
    "- build word2vec model using gensim for word meaning vectors\n",
    "\n",
    "\n",
    "\n",
    "LATER: build doc2vec model using gensim for doc meaning\n",
    "\n",
    "All analyses are first done with only cognitive key words for a sparse but cognition-specific model, then it's repeated with all words for a fuller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim as gs\n",
    "from sklearn import decomposition, metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corpus_from_list(doc_list, terms_dict=None):\n",
    "    # transform doc_list, which is a list of strings where each string is a document, into gensim friendly corpus form\n",
    "    # are you f-ing serious I have to build the corpus feature myself..?\n",
    "    terms = term_dict.keys()\n",
    "    corpus_index = [None]*len(doc_list)\n",
    "    corpus_terms = [None]*len(doc_list)\n",
    "    for doc_ind, doc in enumerate(doc_list):\n",
    "        cur_corp_index = []\n",
    "        cur_corp_terms = []\n",
    "        for term in terms:\n",
    "            # use all lower case to search\n",
    "            t_count = doc.lower().count(term)\n",
    "            if t_count:\n",
    "                cur_corp_index.append((term_dict[term], t_count))\n",
    "                cur_corp_terms.append(term)\n",
    "                \n",
    "        corpus_index[doc_ind] = cur_corp_index\n",
    "        corpus_terms[doc_ind] = cur_corp_terms\n",
    "    \n",
    "    return corpus_index, corpus_terms\n",
    "\n",
    "def terms_similar_to(term_sim, dictionary, query_term='attention', topN=10):\n",
    "    # querying top N similar words\n",
    "    if query_term in dictionary.token2id.keys():\n",
    "        query_ind = dictionary.token2id[query_term]\n",
    "        print('Freq. | Similarity: Term')\n",
    "        print('------------------------')\n",
    "        for i in np.argsort(term_sim[query_ind,:])[::-1][:topN]:\n",
    "            print('%.3f | %.3f: '%(dictionary.dfs[i]/dictionary.num_docs, term_sim[query_ind,i]) + dictionary.id2token[i])\n",
    "            \n",
    "    else:\n",
    "        print(query_term + ' is not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6385 documents extracted.\n"
     ]
    }
   ],
   "source": [
    "# import dictionary (cognitive concept word list)\n",
    "terms_file = '../data/cogatlas_terms.txt'\n",
    "terms = pd.read_csv(terms_file, delimiter='\\n', names=['Terms'])\n",
    "\n",
    "# construct as dictionary\n",
    "# gensim requires dict to be of form {'word':id}, so zip together term list and id numbers\n",
    "term_dict = dict(zip(terms['Terms'], range(len(terms['Terms'])))) \n",
    "\n",
    "# import data as pd dataframe\n",
    "abstract_file = '../data/cogsci_abstracts.csv'\n",
    "col_names = ('Year', 'Title', 'Abstract', 'Authors', 'Affiliations', 'URL')\n",
    "df_cs = pd.read_csv(abstract_file, header=None, names=col_names)\n",
    "print('%i documents extracted.' %len(df_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning document list for dictionary words only...\n"
     ]
    }
   ],
   "source": [
    "# combine title & abstract of each document and put into list\n",
    "doc_list = []\n",
    "for t in range(len(df_cs)):\n",
    "    if type(df_cs['Abstract'][t]) is not str:\n",
    "        doc_list.append(df_cs['Title'][t])\n",
    "    else:\n",
    "        doc_list.append(df_cs['Title'][t]+'. ' + df_cs['Abstract'][t])    \n",
    "        \n",
    "# convert document list into dictionary-words only list, by using the custom dictionary.\n",
    "# if using the whole corpus to build dictionary, just do \n",
    "#     dct = gs.corpora.Dictionary([d.lower() for d in doc_list.lower])\n",
    "print('Pruning document list for dictionary words only...')\n",
    "corpus_index, corpus_terms = corpus_from_list(doc_list=doc_list, terms_dict=term_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis\n",
    "https://en.wikipedia.org/wiki/Latent_semantic_analysis#Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tf-idf model\n",
    "Some questions:\n",
    "- is it necessary to stem the keywords/data?\n",
    "- how best to handle phrases where sub-phrases are also dict phrases (\"memory\" in \"working memory\", \"concept\" in \"conceptual)? (https://stackoverflow.com/questions/4173787/string-exact-match/4173810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(516 unique tokens: ['concept', 'focus', 'goal', 'learning', 'search']...)\n"
     ]
    }
   ],
   "source": [
    "# building tf-idf representation\n",
    "\n",
    "# use gensim to rebuild dictionary, though now the original dictionary that \n",
    "# I build (term_dict) will have different indices than the gensim dict (dct), which\n",
    "# is fine, just need to be careful with indexing and not use the original dict\n",
    "dct = gs.corpora.Dictionary(corpus_terms)\n",
    "print(dct)\n",
    "corpus = [dct.doc2bow(line) for line in corpus_terms]\n",
    "model = gs.models.TfidfModel(corpus, id2word=dct)  # fit model\n",
    "corpus_tfidf = [model[c] for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSA model using tfidf\n",
    "model = gs.models.lsimodel.LsiModel(corpus_tfidf, id2word=dct, num_topics=20)\n",
    "model.print_topics(20)\n",
    "# put topic vectors into a pandas df\n",
    "df = pd.DataFrame([[t[0]+\" %.3f\" %t[1] for t in model.show_topic(i)] for i in range(model.num_topics)])\n",
    "#df\n",
    "index = gs.similarities.MatrixSimilarity(model[corpus_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun little query to show document similarity\n",
    "Looks like document similarity is pretty good! Though this wasn't even what I wanted to get at..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "---0---\n",
      "Childrenâ€™s social referencing reflects sensitivity to graded uncertainty\n",
      "---1---\n",
      "Social and Environmental Contributors to Infant Word Learning\n",
      "---2---\n",
      "What role do you play in group activity? Objective evaluation through third parties\n",
      "---3---\n",
      "Narrowing of the Cone-of-Direct Gaze Through Reinforcement Learning\n",
      "---4---\n",
      "Online Processing of Speech and Social Information in Early Word Learning\n",
      "---5---\n",
      "How does this thing work? Evaluating computational models of intervention-based causal learning\n"
     ]
    }
   ],
   "source": [
    "print_abstr=False\n",
    "doc_num = 100#np.random.randint(len(corpus_tfidf))\n",
    "topN = 5\n",
    "doc_sim = sorted(enumerate(index[model[corpus_tfidf[doc_num]]]), key=lambda item: -item[1])\n",
    "print(doc_num)\n",
    "for i in range(topN+1):\n",
    "    print('---%i---'%i)\n",
    "    print(df_cs['Title'][doc_sim[i][0]])\n",
    "    if print_abstr: print(df_cs['Abstract'][doc_sim[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.257: learning\n",
      "0.228: search\n",
      "0.215: action\n",
      "0.184: language\n",
      "0.151: logic\n",
      "0.126: knowledge\n",
      "0.125: concept\n",
      "0.121: memory\n",
      "0.117: context\n",
      "0.101: decision\n",
      "0.089: attention\n",
      "0.082: reasoning\n",
      "0.080: judgment\n",
      "0.079: focus\n",
      "0.075: lying\n",
      "0.073: inference\n",
      "0.073: perception\n",
      "0.071: meaning\n",
      "0.061: goal\n",
      "0.058: movement\n",
      "0.053: recognition\n",
      "0.047: reading\n",
      "0.046: skill\n",
      "0.044: belief\n",
      "0.043: strategy\n",
      "0.042: rule\n",
      "0.038: emotion\n",
      "0.038: association\n",
      "0.037: communication\n",
      "0.036: categorization\n",
      "0.032: insight\n",
      "0.032: working memory\n",
      "0.032: thought\n",
      "0.032: activation\n",
      "0.028: recall\n",
      "0.028: strength\n",
      "0.026: resource\n",
      "0.026: priming\n",
      "0.026: intention\n",
      "0.026: manipulation\n",
      "0.025: decision making\n",
      "0.025: problem solving\n",
      "0.025: generalization\n",
      "0.024: uncertainty\n",
      "0.023: gaze\n",
      "0.022: integration\n",
      "0.021: conversation\n",
      "0.021: effort\n",
      "0.021: encoding\n",
      "0.020: retrieval\n",
      "0.020: detection\n",
      "0.020: fixation\n",
      "0.019: category learning\n",
      "0.018: valence\n",
      "0.018: metaphor\n",
      "0.017: risk\n",
      "0.017: coordination\n",
      "0.016: discourse\n",
      "0.016: eating\n",
      "0.016: interference\n",
      "0.016: expertise\n",
      "0.016: language acquisition\n",
      "0.014: analogy\n",
      "0.014: intelligence\n",
      "0.014: planning\n",
      "0.014: naming\n",
      "0.014: efficiency\n",
      "0.013: discrimination\n",
      "0.013: language learning\n",
      "0.013: language processing\n",
      "0.012: lexicon\n",
      "0.012: schema\n",
      "0.011: utility\n",
      "0.011: induction\n",
      "0.011: adaptation\n",
      "0.011: familiarity\n",
      "0.011: attitude\n",
      "0.011: balance\n",
      "0.010: salience\n",
      "0.010: mental representation\n",
      "0.010: narrative\n",
      "0.010: visual search\n",
      "0.010: lemma\n",
      "0.010: visual attention\n",
      "0.010: competition\n",
      "0.010: theory of mind\n",
      "0.009: inhibition\n",
      "0.009: reinforcement learning\n",
      "0.009: desire\n",
      "0.009: syntax\n",
      "0.008: updating\n",
      "0.008: loss\n",
      "0.008: word recognition\n",
      "0.008: language comprehension\n",
      "0.008: framing\n",
      "0.008: language production\n",
      "0.007: sentence processing\n",
      "0.007: cognitive development\n",
      "0.007: prototype\n",
      "0.007: chunk\n",
      "0.007: embodied cognition\n",
      "0.007: retention\n",
      "0.007: habit\n",
      "0.007: logical reasoning\n",
      "0.007: cognitive load\n",
      "0.007: monitoring\n",
      "0.007: navigation\n",
      "0.007: listening\n",
      "0.007: object recognition\n",
      "0.006: stress\n",
      "0.006: social cognition\n",
      "0.005: semantic memory\n",
      "0.005: intentionality\n",
      "0.005: analogical reasoning\n",
      "0.005: selective attention\n",
      "0.005: agency\n",
      "0.005: social context\n",
      "0.005: imagery\n",
      "0.005: egocentric\n",
      "0.005: surprise\n",
      "0.005: episodic memory\n",
      "0.005: word order\n",
      "0.005: routine\n",
      "0.005: speech perception\n",
      "0.005: facial expression\n",
      "0.005: sentence comprehension\n",
      "0.005: spatial cognition\n",
      "0.005: long-term memory\n",
      "0.005: semantic information\n",
      "0.005: cognitive control\n",
      "0.005: causal inference\n",
      "0.005: rhythm\n",
      "0.005: prosody\n",
      "0.005: pragmatic inference\n",
      "0.005: semantic processing\n",
      "0.004: anxiety\n",
      "0.004: perceptual learning\n",
      "0.004: concept learning\n",
      "0.004: conceptualization\n",
      "0.004: short-term memory\n",
      "0.004: visual perception\n",
      "0.004: mental rotation\n",
      "0.004: implicit learning\n",
      "0.004: consciousness\n",
      "0.004: semantic network\n",
      "0.004: arousal\n",
      "0.004: spatial memory\n",
      "0.004: parsing\n",
      "0.004: empathy\n",
      "0.004: face recognition\n",
      "0.004: spatial ability\n",
      "0.004: visual representation\n",
      "0.004: forgetting\n",
      "0.004: joint attention\n",
      "0.004: maintenance\n",
      "0.003: inductive reasoning\n",
      "0.003: multisensory\n",
      "0.003: semantic knowledge\n",
      "0.003: pain\n",
      "0.003: metacognition\n",
      "0.003: morphology\n",
      "0.003: motor control\n",
      "0.003: semantic priming\n",
      "0.003: memory retrieval\n",
      "0.003: distraction\n",
      "0.003: anchoring\n",
      "0.003: speech production\n",
      "0.003: mental imagery\n",
      "0.003: categorical perception\n",
      "0.003: acuity\n",
      "0.003: articulation\n",
      "0.003: anticipation\n",
      "0.003: emotional expression\n",
      "0.003: text comprehension\n",
      "0.003: sustained attention\n",
      "0.003: lexical access\n",
      "0.003: sentence production\n",
      "0.003: consolidation\n",
      "0.003: orthography\n",
      "0.003: sequence learning\n",
      "0.003: fear\n",
      "0.003: spatial attention\n",
      "0.003: speech processing\n",
      "0.002: perceptual similarity\n",
      "0.002: deception\n",
      "0.002: attentional resources\n",
      "0.002: guilt\n",
      "0.002: rehearsal\n",
      "0.002: sleep\n",
      "0.002: cueing\n",
      "0.002: wisdom\n",
      "0.002: task difficulty\n",
      "0.002: filtering\n",
      "0.002: humor\n",
      "0.002: memory trace\n",
      "0.002: dyslexia\n",
      "0.002: expectancy\n",
      "0.002: negative emotion\n",
      "0.002: visual working memory\n",
      "0.002: task switching\n",
      "0.002: pronunciation\n",
      "0.002: visual word recognition\n",
      "0.002: visual memory\n",
      "0.002: procedural knowledge\n",
      "0.002: imagination\n",
      "0.002: dispositions\n",
      "0.002: automaticity\n",
      "0.002: cognitive effort\n",
      "0.002: stereotypes\n",
      "0.002: intonation\n",
      "0.002: deductive reasoning\n",
      "0.002: locomotion\n",
      "0.002: mood\n",
      "0.002: declarative memory\n",
      "0.002: spatial working memory\n",
      "0.002: past tense\n",
      "0.002: skill acquisition\n",
      "0.002: abstract knowledge\n",
      "0.002: deliberation\n",
      "0.002: lexical processing\n",
      "0.002: semantic category\n",
      "0.002: crossmodal\n",
      "0.002: pragmatic reasoning\n",
      "0.002: object categorization\n",
      "0.002: relational learning\n",
      "0.002: analogical transfer\n",
      "0.002: false memory\n",
      "0.002: regret\n",
      "0.002: happiness\n",
      "0.002: pattern recognition\n",
      "0.001: conceptual metaphor\n",
      "0.001: melody\n",
      "0.001: chunking\n",
      "0.001: visual recognition\n",
      "0.001: sadness\n",
      "0.001: spreading activation\n",
      "0.001: implicit memory\n",
      "0.001: attachment\n",
      "0.001: syntactic processing\n",
      "0.001: mental arithmetic\n",
      "0.001: attentional bias\n",
      "0.001: analogical problem solving\n",
      "0.001: proactive interference\n",
      "0.001: context dependent\n",
      "0.001: visual object recognition\n",
      "0.001: task set\n",
      "0.001: memory decay\n",
      "0.001: motor learning\n",
      "0.001: processing speed\n",
      "0.001: response bias\n",
      "0.001: object perception\n",
      "0.001: multisensory integration\n",
      "0.001: intertemporal choice\n",
      "0.001: localization\n",
      "0.001: conditional reasoning\n",
      "0.001: analogical inference\n",
      "0.001: goal state\n",
      "0.001: response selection\n",
      "0.001: face perception\n",
      "0.001: cue validity\n",
      "0.001: prejudice\n",
      "0.001: explicit knowledge\n",
      "0.001: implicit knowledge\n",
      "0.001: rule learning\n",
      "0.001: auditory perception\n",
      "0.001: motor planning\n",
      "0.001: explicit learning\n",
      "0.001: explicit memory\n",
      "0.001: motor program\n",
      "0.001: curiosity\n",
      "0.001: memory consolidation\n",
      "0.001: altruism\n",
      "0.001: creative problem solving\n",
      "0.001: change blindness\n",
      "0.001: verbal memory\n",
      "0.001: response inhibition\n",
      "0.001: creative thinking\n",
      "0.001: emotion recognition\n",
      "0.001: audition\n",
      "0.001: dream\n",
      "0.001: imageability\n",
      "0.001: metacomprehension\n",
      "0.001: fatigue\n",
      "0.001: attention shift\n",
      "0.001: confidence judgment\n",
      "0.001: overt attention\n",
      "0.001: serial search\n",
      "0.001: inattention\n",
      "0.001: irony\n",
      "0.001: instinct\n",
      "0.001: fluid intelligence\n",
      "0.001: social inference\n",
      "0.001: emotion perception\n",
      "0.001: incidental learning\n",
      "0.001: metacognitive skill\n",
      "0.001: delusion\n",
      "0.001: cognitive map\n",
      "0.001: intrinsic motivation\n",
      "0.001: retrieval cue\n",
      "0.001: discourse comprehension\n",
      "0.001: text processing\n",
      "0.001: focused attention\n",
      "0.001: worldview\n",
      "0.001: object manipulation\n",
      "0.001: word repetition\n",
      "0.001: assimilation\n",
      "0.001: word comprehension\n",
      "0.001: processing stage\n",
      "0.001: prospective memory\n",
      "0.001: visual angle\n",
      "0.001: processing capacity\n",
      "0.001: openness\n",
      "0.001: mathematical reasoning\n",
      "0.001: attentional blink\n",
      "0.001: impulsivity\n",
      "0.001: auditory feedback\n",
      "0.001: conceptual priming\n",
      "0.001: incubation\n",
      "0.001: episodic future thinking\n",
      "0.001: divergent thinking\n",
      "0.001: adaptive control\n",
      "0.001: phonological loop\n",
      "0.001: connotation\n",
      "0.001: loss aversion\n",
      "0.001: procedural memory\n",
      "0.001: activation level\n",
      "0.001: retroactive interference\n",
      "0.001: social intelligence\n",
      "0.001: unisensory\n",
      "0.001: numerical comparison\n",
      "0.001: skepticism\n",
      "0.001: lexeme\n",
      "0.001: phonological awareness\n",
      "0.001: frustration\n",
      "0.001: phonological processing\n",
      "0.001: cognitive training\n",
      "0.001: extinction\n",
      "0.000: apparent motion\n",
      "0.000: gestalt\n",
      "0.000: covert attention\n",
      "0.000: declarative knowledge\n",
      "0.000: introspection\n",
      "0.000: phonological working memory\n",
      "0.000: inattentional blindness\n",
      "0.000: source memory\n",
      "0.000: phonetics\n",
      "0.000: constancy\n",
      "0.000: response conflict\n",
      "0.000: central executive\n",
      "0.000: risk aversion\n",
      "0.000: addiction\n",
      "0.000: attentional state\n",
      "0.000: hallucination\n",
      "0.000: visual imagery\n",
      "0.000: lexical retrieval\n",
      "0.000: coreference\n",
      "0.000: contingency learning\n",
      "0.000: color perception\n",
      "0.000: reinstatement\n",
      "0.000: circadian rhythm\n",
      "0.000: grammatical encoding\n",
      "0.000: phonological code\n",
      "0.000: conventionality\n",
      "0.000: emotional intelligence\n",
      "0.000: sensory memory\n",
      "0.000: lexical ambiguity\n",
      "0.000: morphological processing\n",
      "0.000: serial processing\n",
      "0.000: action perception\n",
      "0.000: active maintenance\n",
      "0.000: inhibition of return\n",
      "0.000: repetition priming\n",
      "0.000: effortful processing\n",
      "0.000: conflict detection\n",
      "0.000: abductive reasoning\n",
      "0.000: emotion regulation\n",
      "0.000: convergent thinking\n",
      "0.000: body representation\n",
      "0.000: conceptual category\n",
      "0.000: story comprehension\n",
      "0.000: capacity limitation\n",
      "0.000: proactive control\n",
      "0.000: visual awareness\n",
      "0.000: deep processing\n",
      "0.000: binocular rivalry\n",
      "0.000: error detection\n",
      "0.000: feature extraction\n",
      "0.000: procedural learning\n",
      "0.000: phonological encoding\n",
      "0.000: categorical knowledge\n",
      "0.000: social motivation\n",
      "0.000: perceptual identification\n",
      "0.000: vection\n",
      "0.000: unconscious process\n",
      "0.000: negative priming\n",
      "0.000: route knowledge\n",
      "0.000: proprioception\n",
      "0.000: perceptual categorization\n",
      "0.000: phonological buffer\n",
      "0.000: attention shifting\n",
      "0.000: heuristic search\n",
      "0.000: positive priming\n",
      "0.000: pavlovian conditioning\n",
      "0.000: motion aftereffect\n",
      "0.000: motor sequence learning\n",
      "0.000: semantic categorization\n",
      "0.000: iconic memory\n",
      "0.000: facial recognition\n",
      "0.000: deductive inference\n",
      "0.000: object detection\n",
      "0.000: amodal representation\n",
      "0.000: crowding\n",
      "0.000: constituent structure\n",
      "0.000: conjunction search\n",
      "0.000: perceptual skill\n",
      "0.000: verbal fluency\n",
      "0.000: excitation\n",
      "0.000: discourse processing\n",
      "0.000: prospection\n",
      "0.000: transduction\n",
      "0.000: interrogative\n",
      "0.000: grapheme\n",
      "0.000: auditory imagery\n",
      "0.000: global precedence\n",
      "0.000: autobiographical memory\n",
      "0.000: motion detection\n",
      "0.000: perceptual fluency\n",
      "0.000: centration\n",
      "0.000: interference control\n",
      "0.000: creative cognition\n",
      "0.000: error signal\n",
      "0.000: olfaction\n",
      "0.000: reconsolidation\n",
      "0.000: interference resolution\n",
      "0.000: syntactic parsing\n",
      "0.000: attention span\n",
      "0.000: elaborative processing\n",
      "0.000: analog representation\n",
      "0.000: cognitive dissonance\n",
      "0.000: contextual knowledge\n",
      "0.000: memory storage\n",
      "0.000: sense of body ownership\n",
      "0.000: novelty detection\n",
      "0.000: perceptual binding\n",
      "0.000: deep structure\n",
      "0.000: word pronunciation\n",
      "0.000: conflict adaptation effect\n",
      "0.000: self control\n",
      "0.000: depth perception\n",
      "0.000: word generation\n",
      "0.000: working memory maintenance\n",
      "0.000: animacy perception\n",
      "0.000: attended stimulus\n",
      "0.000: critical period\n",
      "0.000: divided attention\n",
      "0.000: conceptual coherence\n",
      "0.000: visual acuity\n",
      "0.000: emotional enhancement\n",
      "0.000: domain specificity\n",
      "0.000: neologism\n",
      "0.000: crosstalk\n",
      "0.000: voice perception\n",
      "0.000: discourse production\n",
      "0.000: discourse planning\n",
      "0.000: pragmatic knowledge\n",
      "0.000: difference threshold\n",
      "0.000: subconscious\n",
      "0.000: oddball detection\n",
      "0.000: supervisory attentional system\n",
      "0.000: procedural rule\n",
      "0.000: visual orientation\n",
      "0.000: exogenous attention\n",
      "0.000: auditory working memory\n",
      "0.000: sensitivity to change\n",
      "0.000: involuntary attention\n",
      "0.000: shame\n",
      "0.000: color constancy\n",
      "0.000: risk seeking\n",
      "0.000: lexical encoding\n",
      "0.000: arithmetic processing\n",
      "0.000: gestalt grouping\n",
      "0.000: body orientation\n",
      "0.000: feature integration\n",
      "0.000: shallow processing\n",
      "0.000: response execution\n",
      "0.000: auditory recognition\n",
      "0.000: visual masking\n",
      "0.000: spontaneous recovery\n",
      "0.000: associative priming\n",
      "0.000: psychological refractory period\n",
      "0.000: availability heuristic\n",
      "0.000: shape recognition\n",
      "0.000: form perception\n",
      "0.000: semantic working memory\n",
      "0.000: metamemory\n",
      "0.000: object-based attention\n",
      "0.000: feature detection\n",
      "0.000: relational comparison\n",
      "0.000: emotional memory\n",
      "0.000: feature-based attention\n",
      "0.000: misattribution\n",
      "0.000: conversational speech\n",
      "0.000: visual pattern recognition\n",
      "0.000: goal management\n",
      "0.000: interoception\n",
      "0.000: intentional forgetting\n",
      "0.000: decision under uncertainty\n",
      "0.000: auditory memory\n",
      "0.000: auditory stream segregation\n",
      "0.000: resource limit\n",
      "0.000: serial learning\n",
      "0.000: working memory updating\n",
      "0.000: generic knowledge\n",
      "0.000: cognitive heuristic\n",
      "0.000: context representation\n",
      "0.000: neuroplasticity\n"
     ]
    }
   ],
   "source": [
    "# word frequency\n",
    "for t in np.argsort([dct.dfs[t] for t in range(len(dct.dfs))])[::-1]:    \n",
    "    print('%.3f: '%(dct.dfs[t]/dct.num_docs) + dct.id2token[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Similarity Matrix: (516, 516)\n"
     ]
    }
   ],
   "source": [
    "# scipy SVD to compute term similarity\n",
    "num_comp = 200\n",
    "\n",
    "# get dense matrix to do SVD in scipy to compare word similarities\n",
    "mat_tfidf = gs.matutils.corpus2dense(corpus_tfidf, len(dct.dfs))\n",
    "TSVD = decomposition.TruncatedSVD(n_components=num_comp)\n",
    "TSVD.fit_transform(mat_tfidf.T)\n",
    "U = TSVD.components_\n",
    "TSVD.fit_transform(mat_tfidf)\n",
    "V = TSVD.components_\n",
    "S = np.diag(TSVD.singular_values_)\n",
    "\n",
    "# get transformed word vectors\n",
    "t_star = np.matmul(S,U).T\n",
    "\n",
    "# word similarity from raw tfidf matrix\n",
    "term_sim_raw = metrics.pairwise.cosine_similarity(mat_tfidf) \n",
    "# word similarity from LSA transformed matrix\n",
    "term_sim_LSA = metrics.pairwise.cosine_similarity(t_star)\n",
    "print('Term Similarity Matrix: (%i, %i)'%term_sim_LSA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq. | Similarity: Term\n",
      "------------------------\n",
      "0.028 | 1.000: recall\n",
      "0.000 | 0.512: emotional enhancement\n",
      "0.000 | 0.417: emotional memory\n",
      "0.000 | 0.410: divided attention\n",
      "0.000 | 0.390: gestalt grouping\n",
      "0.000 | 0.323: story comprehension\n",
      "0.121 | 0.265: memory\n",
      "0.000 | 0.247: attentional state\n",
      "0.000 | 0.227: body orientation\n",
      "0.000 | 0.204: heuristic search\n",
      "0.001 | 0.171: discourse comprehension\n",
      "0.001 | 0.164: retrieval cue\n",
      "0.000 | 0.163: autobiographical memory\n",
      "0.002 | 0.153: declarative memory\n",
      "0.002 | 0.149: rehearsal\n",
      "0.000 | 0.143: gestalt\n",
      "0.000 | 0.135: visual imagery\n",
      "0.001 | 0.133: cognitive map\n",
      "0.001 | 0.127: localization\n",
      "0.020 | 0.123: retrieval\n"
     ]
    }
   ],
   "source": [
    "terms_similar_to(term_sim_LSA, dct, 'recall', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
