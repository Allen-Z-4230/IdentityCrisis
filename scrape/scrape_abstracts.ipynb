{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping abstract information\n",
    "March 4, 2018\n",
    "This notebook scrapes abstract text from:\n",
    "- Proceedings of the Annual Cognitive Science Society meeting archive (html)\n",
    "- Proceedings of Cognitive Neuroscience Society annual meeting (text converted from pdf)\n",
    "\n",
    "Abstracts are then stored in a spreadsheet, containing information such as year, authors, title, and abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_CS(home_url, data_file):\n",
    "    #connect to home page url for that year\n",
    "    CSurl = urllib.request.urlopen(home_url).read()\n",
    "    soup = BeautifulSoup(CSurl, 'html.parser')\n",
    "    all_links = soup.find_all('a', attrs={'href': re.compile(\"papers/*\")})    \n",
    "    year = home_url[-5:-1]    \n",
    "    \n",
    "    # enumerate through all paper links\n",
    "    for link_idx, link in enumerate(all_links):\n",
    "        # get soup from paper url\n",
    "        if home_url not in str(link['href']):\n",
    "            url_text = home_url + str(link['href'])\n",
    "        else:\n",
    "            url_text = str(link['href'])\n",
    "    \n",
    "        url = urllib.request.urlopen(url_text).read()\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "    \n",
    "        # scrape & parse\n",
    "        authors = []\n",
    "        affl = []\n",
    "        title = ' '.join(soup.find_all('h1')[0].text.split())\n",
    "        # exception rule for 2014 abstracts\n",
    "        if '2014' in home_url:            \n",
    "            abstr = ' '.join(soup.find_all('blockquote')[1].text.split())\n",
    "        else:            \n",
    "            abstr = ' '.join(soup.find_all('p', {\"id\": \"abstract\"})[0].text.split())            \n",
    "        \n",
    "        soup.find_all('ul')\n",
    "        for ana in soup.find_all('em'):\n",
    "            affl.append('>'+ana.text)\n",
    "            if '2014' in home_url:\n",
    "                # somebody fucked something up in 2014\n",
    "                authors.append('>' + ana.previous_element.previous_element.split(',')[0])\n",
    "            else:            \n",
    "                authors.append('>' + ana.previous_element.split(',')[0])\n",
    "        \n",
    "        # do some gymnastics to get it into a pandas df and add as a row to CSV\n",
    "        new_row = {'Year': str(year), 'Title': title,'Abstract': abstr,'Authors': ''.join(authors),'Affiliations': ''.join(affl), 'URL': url_text}\n",
    "        df_cur = pd.Series(data=new_row).to_frame().T[['Year','Title','Abstract','Authors','Affiliations','URL']]\n",
    "        df_cur.to_csv(data_file, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mindmodeling.org/cogsci2017/\n",
      "https://mindmodeling.org/cogsci2016/\n",
      "https://mindmodeling.org/cogsci2015/\n",
      "https://mindmodeling.org/cogsci2014/\n",
      "https://mindmodeling.org/cogsci2013/\n",
      "https://mindmodeling.org/cogsci2012/\n",
      "https://mindmodeling.org/cogsci2011/\n",
      "https://mindmodeling.org/cogsci2010/\n"
     ]
    }
   ],
   "source": [
    "# get all paper links from cogsci conference\n",
    "home_urls = ['https://mindmodeling.org/cogsci2017/',\n",
    "             'https://mindmodeling.org/cogsci2016/',\n",
    "             'https://mindmodeling.org/cogsci2015/',\n",
    "             'https://mindmodeling.org/cogsci2014/',\n",
    "             'https://mindmodeling.org/cogsci2013/',\n",
    "             'https://mindmodeling.org/cogsci2012/',\n",
    "             'https://mindmodeling.org/cogsci2011/',\n",
    "             'https://mindmodeling.org/cogsci2010/']\n",
    "\n",
    "for year in home_urls:\n",
    "    # scrape all\n",
    "    print(year)\n",
    "    scrape_CS(home_url=year, data_file='../data/cogsci_abstracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather CNS abstracts from text to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '../data/CNS_programs/'\n",
    "os.listdir(data_folder)\n",
    "CNS_files = sorted([f for f in os.listdir(data_folder) if ('CNS' in f) and ('.txt' in f)])\n",
    "CNS_files\n",
    "\n",
    "file = open(data_folder+CNS_files[0], 'r')\n",
    "data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 29623\n"
     ]
    }
   ],
   "source": [
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if 'Graduate Students Present Abstracts' in d][-1]\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = next((ind for ind,s in enumerate(abs_list) if 'Poster Session A' == s.strip()), None)\n",
    "poster_end_ind = next((ind for ind,s in enumerate(abs_list) if 'Author Index' == s.strip()), None)\n",
    "print(poster_beg_ind, poster_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Poster Session A'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_num_sess(abs_list, poster_beg_ind):\n",
    "    # find the number of poster sessions from the schedule section\n",
    "    sched = abs_list[:poster_beg_ind]\n",
    "    for ind, sess in enumerate(string.ascii_uppercase):\n",
    "        if sess not in sched:  \n",
    "            return string.ascii_uppercase[:ind]\n",
    "\n",
    "sess = find_num_sess(abs_list, poster_beg_ind)\n",
    "\n",
    "'Poster Session ' + sess[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A2',\n",
       " 'BENEFITS OF OPTOKINETIC STIMULATION IN PATIENTS WITH',\n",
       " 'AUDITORY AND VISUAL NEGLECT: TRANSIENT AND',\n",
       " 'PERMANENT EFFECTS Georg Kerkhoff1,2, Christian Groh-Bordin1, Ingo',\n",
       " 'Keller3, Vera Ritter2, Frank Artinger4, Wolfram Ziegler2; 1Saarland University,',\n",
       " 'Saarbruecken, Germany, 2Clinical Neuropsychology Research Group, MunichBogenhausen, Germany, 3Neurological Clinic Bad Aibling, Germany,',\n",
       " '4University of Applied Sciences, Karlsruhe, Germany — Unilateral',\n",
       " 'neglect',\n",
       " 'after right cerebral stroke involves visual and auditory impairments in orientation and exploration of contralesional stimuli. Several treatments –',\n",
       " 'mostly focussing on visual neglect - have been proposed: prism adaptation, pharmacological treatments and optokinetic stimulation (OKS).']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_list[A1[0]:A1[0]+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
