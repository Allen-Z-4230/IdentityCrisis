{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping abstract information\n",
    "March 4, 2018\n",
    "This notebook scrapes abstract text from:\n",
    "- Proceedings of the Annual Cognitive Science Society meeting archive (html)\n",
    "- Proceedings of Cognitive Neuroscience Society annual meeting (text converted from pdf)\n",
    "\n",
    "Abstracts are then stored in a spreadsheet, containing information such as year, authors, title, and abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_CS(home_url, data_file):\n",
    "    #connect to home page url for that year\n",
    "    CSurl = urllib.request.urlopen(home_url).read()\n",
    "    soup = BeautifulSoup(CSurl, 'html.parser')\n",
    "    all_links = soup.find_all('a', attrs={'href': re.compile(\"papers/*\")})    \n",
    "    year = home_url[-5:-1]    \n",
    "    \n",
    "    # enumerate through all paper links\n",
    "    for link_idx, link in enumerate(all_links):\n",
    "        # get soup from paper url\n",
    "        if home_url not in str(link['href']):\n",
    "            url_text = home_url + str(link['href'])\n",
    "        else:\n",
    "            url_text = str(link['href'])\n",
    "    \n",
    "        url = urllib.request.urlopen(url_text).read()\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "    \n",
    "        # scrape & parse\n",
    "        authors = []\n",
    "        affl = []\n",
    "        title = ' '.join(soup.find_all('h1')[0].text.split())\n",
    "        # exception rule for 2014 abstracts\n",
    "        if '2014' in home_url:            \n",
    "            abstr = ' '.join(soup.find_all('blockquote')[1].text.split())\n",
    "        else:            \n",
    "            abstr = ' '.join(soup.find_all('p', {\"id\": \"abstract\"})[0].text.split())            \n",
    "        \n",
    "        soup.find_all('ul')\n",
    "        for ana in soup.find_all('em'):\n",
    "            affl.append('>'+ana.text)\n",
    "            if '2014' in home_url:\n",
    "                # somebody fucked something up in 2014\n",
    "                authors.append('>' + ana.previous_element.previous_element.split(',')[0])\n",
    "            else:            \n",
    "                authors.append('>' + ana.previous_element.split(',')[0])\n",
    "        \n",
    "        # do some gymnastics to get it into a pandas df and add as a row to CSV\n",
    "        new_row = {'Year': str(year), 'Title': title,'Abstract': abstr,'Authors': ''.join(authors),'Affiliations': ''.join(affl), 'URL': url_text}\n",
    "        df_cur = pd.Series(data=new_row).to_frame().T[['Year','Title','Abstract','Authors','Affiliations','URL']]\n",
    "        df_cur.to_csv(data_file, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all paper links from cogsci conference\n",
    "home_urls = ['https://mindmodeling.org/cogsci2017/',\n",
    "             'https://mindmodeling.org/cogsci2016/',\n",
    "             'https://mindmodeling.org/cogsci2015/',\n",
    "             'https://mindmodeling.org/cogsci2014/',\n",
    "             'https://mindmodeling.org/cogsci2013/',\n",
    "             'https://mindmodeling.org/cogsci2012/',\n",
    "             'https://mindmodeling.org/cogsci2011/',\n",
    "             'https://mindmodeling.org/cogsci2010/']\n",
    "\n",
    "for year in home_urls:\n",
    "    # scrape all\n",
    "    print(year)\n",
    "    scrape_CS(home_url=year, data_file='../data/cogsci_abstracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather CNS abstracts from text to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNS_2007_Program.txt', 'CNS_2008_Program.txt', 'CNS_2009_Program.txt', 'CNS_2010_Program.txt', 'CNS_2011_Program.txt', 'CNS_2012_Program.txt', 'CNS_2013_Program.txt', 'CNS_2014_Program.txt', 'CNS_2015_Program.txt', 'CNS_2016_Program.txt']\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../data/CNS_programs/'\n",
    "os.listdir(data_folder)\n",
    "CNS_files = sorted([f for f in os.listdir(data_folder) if ('CNS' in f) and ('.txt' in f)])[:-1]\n",
    "print(CNS_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#col_names = ['CNS_file','start_sect','beg_ind','end_ind']\n",
    "\n",
    "#reffering to the abs_list problem encountered in journal on 8/2/2018. I think this needs to be on the outside of the loop so that it can catch each abs_list year change\n",
    "\n",
    "\n",
    "CNS_file=[]\n",
    "start_sect=[]\n",
    "beg_ind=[]\n",
    "end_ind=[]\n",
    "\n",
    "for i in range(len(CNS_files)):\n",
    "    \n",
    "    CNS_file.append(CNS_files[i])\n",
    "    \n",
    "    #print(CNS_files[i])\n",
    "    file = open(data_folder+CNS_files[i], 'r')#the 8 is supposed to be \"i\" but I think that it is grabbing the last one and using that to make abs list each time \n",
    "    data = file.read()\n",
    "    data_list = data.split('\\n')\n",
    "    abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "    \n",
    "    start_sect.append([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    #print([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    \n",
    "    abs_list = data_list[abs_start:]\n",
    "    poster_beg_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cPoster Session A' == s), None)    \n",
    "    poster_end_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cAuthor Index' == s), None)\n",
    "    \n",
    "    \n",
    "    beg_ind.append(poster_beg_ind)\n",
    "    \n",
    "    end_ind.append(poster_end_ind)\n",
    "    \n",
    "    \n",
    "    #print(poster_beg_ind, poster_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNS_file</th>\n",
       "      <th>beg_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>start_sect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNS_2007_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>29493</td>\n",
       "      <td>[1456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNS_2008_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>30363</td>\n",
       "      <td>[1538, 1748, 1969, 2189, 2414, 2647, 2884, 311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNS_2009_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>23882</td>\n",
       "      <td>[2181, 2395, 2613, 2834, 3076, 3310, 3545, 379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNS_2010_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>31628</td>\n",
       "      <td>[3236, 3472, 3718, 3974, 4229, 4460, 4694, 495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNS_2011_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>24580</td>\n",
       "      <td>[3326, 3420, 3667, 3907, 4148, 4394, 4628, 487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNS_2012_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>24793</td>\n",
       "      <td>[3516, 3610, 3848, 4113, 4353, 4587, 4836, 507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNS_2013_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28381</td>\n",
       "      <td>[2881, 3128, 3372, 3626, 3852, 4106, 4348, 459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNS_2014_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28084</td>\n",
       "      <td>[3137, 3250, 3505, 3753, 4009, 4253, 4493, 475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNS_2015_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>23909</td>\n",
       "      <td>[3350, 3588, 3829, 4068, 4322, 4566, 4823, 506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNS_2016_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28305</td>\n",
       "      <td>[3593, 3823, 4072, 4313, 4566, 4827, 5087, 533...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CNS_file  beg_ind  end_ind  \\\n",
       "0  CNS_2007_Program.txt        0    29493   \n",
       "1  CNS_2008_Program.txt        0    30363   \n",
       "2  CNS_2009_Program.txt        0    23882   \n",
       "3  CNS_2010_Program.txt        0    31628   \n",
       "4  CNS_2011_Program.txt        0    24580   \n",
       "5  CNS_2012_Program.txt        0    24793   \n",
       "6  CNS_2013_Program.txt        0    28381   \n",
       "7  CNS_2014_Program.txt        0    28084   \n",
       "8  CNS_2015_Program.txt        0    23909   \n",
       "9  CNS_2016_Program.txt        0    28305   \n",
       "\n",
       "                                          start_sect  \n",
       "0                                             [1456]  \n",
       "1  [1538, 1748, 1969, 2189, 2414, 2647, 2884, 311...  \n",
       "2  [2181, 2395, 2613, 2834, 3076, 3310, 3545, 379...  \n",
       "3  [3236, 3472, 3718, 3974, 4229, 4460, 4694, 495...  \n",
       "4  [3326, 3420, 3667, 3907, 4148, 4394, 4628, 487...  \n",
       "5  [3516, 3610, 3848, 4113, 4353, 4587, 4836, 507...  \n",
       "6  [2881, 3128, 3372, 3626, 3852, 4106, 4348, 459...  \n",
       "7  [3137, 3250, 3505, 3753, 4009, 4253, 4493, 475...  \n",
       "8  [3350, 3588, 3829, 4068, 4322, 4566, 4823, 506...  \n",
       "9  [3593, 3823, 4072, 4313, 4566, 4827, 5087, 533...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cns_frame=pd.DataFrame({'CNS_file':CNS_file,'start_sect':start_sect,'beg_ind':beg_ind,'end_ind':end_ind})\n",
    "cns_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-33-81cd90e6f368>, line 144)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-81cd90e6f368>\"\u001b[0;36m, line \u001b[0;32m144\u001b[0m\n\u001b[0;31m    #             pass\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "\n",
    "last_index = 0\n",
    "let_vec = ['A','B','C']\n",
    "\n",
    "for j in let_vec:\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= j\n",
    "            cur_abs=i+1\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "\n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                    last_index = cur_section+'%i'%(cur_abs+1)\n",
    "                    #print('index found')\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    \n",
    "                    print('k = ',k)\n",
    "                    print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                except: \n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    pass\n",
    "\n",
    "                print(last_index)\n",
    "\n",
    "\n",
    "\n",
    "#         except:\n",
    "#                     abs_beg_ind = abs_list.index(last_index)\n",
    "#                     abs_end_ind = abs_list.index((j+1[1]))\n",
    "                    \n",
    "#                     section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#                     #     print(section_abst)\n",
    "#                     #     print(cur_section+'%i'%(cur_abs+1))\n",
    "#                     #     print(i, abs_beg_ind, abs_end_ind)\n",
    "#                     start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "#                     start_string=last_index #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "#                     whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "#                     title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "#                     title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "#                     title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "#                     length_title_lst=' '.join(title_lst)\n",
    "#                     remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "#                     auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "#                     sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "#                     abst.append(whole_abs)\n",
    "#                     title.append(remove_start_string)\n",
    "#                     #auth.append(title_sect) old wrong way of getting author\n",
    "#                     auth.append(auth_sect)\n",
    "#             last_index\n",
    "#             # letter + last index up to B1 \n",
    "#             # section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract\n",
    "\n",
    "#             pass\n",
    "\n",
    "#         else:\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-34-d0c9b7cf8724>, line 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-d0c9b7cf8724>\"\u001b[0;36m, line \u001b[0;32m108\u001b[0m\n\u001b[0;31m    print(last_index)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "\n",
    "last_index = 0\n",
    "let_vec = ['A','B','C']\n",
    "\n",
    "for j in let_vec:\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= j\n",
    "            cur_abs=i+1\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "\n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                    last_index = cur_section+'%i'%(cur_abs+1)\n",
    "                    #print('index found')\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    \n",
    "                    print('k = ',k)\n",
    "                    print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                except: \n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    pass\n",
    "\n",
    "                print(last_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_end_ind = abs_list.index((cur_section+1'%i'%(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "data_list = data.split('\\n')\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session B')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "#data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session B')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='B'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session C')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session D')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session C')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='C'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session D')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session E')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session D')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='D'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session E')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session F')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session E')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='E'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session F')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session G')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session F')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='F'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session G')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session H')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session G')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='G'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session H')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session I')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session H')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='H'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session I')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Topic Index')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session I')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='I'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        \n",
    "        \n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_table.to_csv(\"CNS_2012_SCRAPED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing another year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[6], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='A'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "data_list = data.split('\\n')\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session B')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[6], 'r')\n",
    "data = file.read()\n",
    "#data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session B')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='B'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session C')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session D')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session C')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='C'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
