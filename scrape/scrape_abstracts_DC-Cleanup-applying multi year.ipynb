{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping abstract information\n",
    "March 4, 2018\n",
    "This notebook scrapes abstract text from:\n",
    "- Proceedings of the Annual Cognitive Science Society meeting archive (html)\n",
    "- Proceedings of Cognitive Neuroscience Society annual meeting (text converted from pdf)\n",
    "\n",
    "Abstracts are then stored in a spreadsheet, containing information such as year, authors, title, and abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_CS(home_url, data_file):\n",
    "    #connect to home page url for that year\n",
    "    CSurl = urllib.request.urlopen(home_url).read()\n",
    "    soup = BeautifulSoup(CSurl, 'html.parser')\n",
    "    all_links = soup.find_all('a', attrs={'href': re.compile(\"papers/*\")})    \n",
    "    year = home_url[-5:-1]    \n",
    "    \n",
    "    # enumerate through all paper links\n",
    "    for link_idx, link in enumerate(all_links):\n",
    "        # get soup from paper url\n",
    "        if home_url not in str(link['href']):\n",
    "            url_text = home_url + str(link['href'])\n",
    "        else:\n",
    "            url_text = str(link['href'])\n",
    "    \n",
    "        url = urllib.request.urlopen(url_text).read()\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "    \n",
    "        # scrape & parse\n",
    "        authors = []\n",
    "        affl = []\n",
    "        title = ' '.join(soup.find_all('h1')[0].text.split())\n",
    "        # exception rule for 2014 abstracts\n",
    "        if '2014' in home_url:            \n",
    "            abstr = ' '.join(soup.find_all('blockquote')[1].text.split())\n",
    "        else:            \n",
    "            abstr = ' '.join(soup.find_all('p', {\"id\": \"abstract\"})[0].text.split())            \n",
    "        \n",
    "        soup.find_all('ul')\n",
    "        for ana in soup.find_all('em'):\n",
    "            affl.append('>'+ana.text)\n",
    "            if '2014' in home_url:\n",
    "                # somebody fucked something up in 2014\n",
    "                authors.append('>' + ana.previous_element.previous_element.split(',')[0])\n",
    "            else:            \n",
    "                authors.append('>' + ana.previous_element.split(',')[0])\n",
    "        \n",
    "        # do some gymnastics to get it into a pandas df and add as a row to CSV\n",
    "        new_row = {'Year': str(year), 'Title': title,'Abstract': abstr,'Authors': ''.join(authors),'Affiliations': ''.join(affl), 'URL': url_text}\n",
    "        df_cur = pd.Series(data=new_row).to_frame().T[['Year','Title','Abstract','Authors','Affiliations','URL']]\n",
    "        df_cur.to_csv(data_file, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all paper links from cogsci conference\n",
    "home_urls = ['https://mindmodeling.org/cogsci2017/',\n",
    "             'https://mindmodeling.org/cogsci2016/',\n",
    "             'https://mindmodeling.org/cogsci2015/',\n",
    "             'https://mindmodeling.org/cogsci2014/',\n",
    "             'https://mindmodeling.org/cogsci2013/',\n",
    "             'https://mindmodeling.org/cogsci2012/',\n",
    "             'https://mindmodeling.org/cogsci2011/',\n",
    "             'https://mindmodeling.org/cogsci2010/']\n",
    "\n",
    "for year in home_urls:\n",
    "    # scrape all\n",
    "    print(year)\n",
    "    scrape_CS(home_url=year, data_file='../data/cogsci_abstracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather CNS abstracts from text to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNS_2007_Program.txt', 'CNS_2008_Program.txt', 'CNS_2009_Program.txt', 'CNS_2010_Program.txt', 'CNS_2011_Program.txt', 'CNS_2012_Program.txt', 'CNS_2013_Program.txt', 'CNS_2014_Program.txt', 'CNS_2015_Program.txt', 'CNS_2016_Program.txt']\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../data/CNS_programs/'\n",
    "os.listdir(data_folder)\n",
    "CNS_files = sorted([f for f in os.listdir(data_folder) if ('CNS' in f) and ('.txt' in f)])[:-1]\n",
    "print(CNS_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#col_names = ['CNS_file','start_sect','beg_ind','end_ind']\n",
    "\n",
    "#reffering to the abs_list problem encountered in journal on 8/2/2018. I think this needs to be on the outside of the loop so that it can catch each abs_list year change\n",
    "\n",
    "\n",
    "CNS_file=[]\n",
    "start_sect=[]\n",
    "beg_ind=[]\n",
    "end_ind=[]\n",
    "\n",
    "for i in range(len(CNS_files)):\n",
    "    \n",
    "    CNS_file.append(CNS_files[i])\n",
    "    \n",
    "    #print(CNS_files[i])\n",
    "    file = open(data_folder+CNS_files[i], 'r')#the 8 is supposed to be \"i\" but I think that it is grabbing the last one and using that to make abs list each time \n",
    "    data = file.read()\n",
    "    data_list = data.split('\\n')\n",
    "    abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "    \n",
    "    start_sect.append([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    #print([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    \n",
    "    abs_list = data_list[abs_start:]\n",
    "    poster_beg_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cPoster Session A' == s), None)    \n",
    "    poster_end_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cAuthor Index' == s), None)\n",
    "    \n",
    "    \n",
    "    beg_ind.append(poster_beg_ind)\n",
    "    \n",
    "    end_ind.append(poster_end_ind)\n",
    "    \n",
    "    \n",
    "    #print(poster_beg_ind, poster_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNS_file</th>\n",
       "      <th>beg_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>start_sect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNS_2007_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>29493</td>\n",
       "      <td>[1456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNS_2008_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>30363</td>\n",
       "      <td>[1538, 1748, 1969, 2189, 2414, 2647, 2884, 311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNS_2009_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>23882</td>\n",
       "      <td>[2181, 2395, 2613, 2834, 3076, 3310, 3545, 379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNS_2010_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>31628</td>\n",
       "      <td>[3236, 3472, 3718, 3974, 4229, 4460, 4694, 495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNS_2011_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>24580</td>\n",
       "      <td>[3326, 3420, 3667, 3907, 4148, 4394, 4628, 487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNS_2012_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>24793</td>\n",
       "      <td>[3516, 3610, 3848, 4113, 4353, 4587, 4836, 507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNS_2013_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28381</td>\n",
       "      <td>[2881, 3128, 3372, 3626, 3852, 4106, 4348, 459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNS_2014_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28084</td>\n",
       "      <td>[3137, 3250, 3505, 3753, 4009, 4253, 4493, 475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNS_2015_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>23909</td>\n",
       "      <td>[3350, 3588, 3829, 4068, 4322, 4566, 4823, 506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNS_2016_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28305</td>\n",
       "      <td>[3593, 3823, 4072, 4313, 4566, 4827, 5087, 533...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CNS_file  beg_ind  end_ind  \\\n",
       "0  CNS_2007_Program.txt        0    29493   \n",
       "1  CNS_2008_Program.txt        0    30363   \n",
       "2  CNS_2009_Program.txt        0    23882   \n",
       "3  CNS_2010_Program.txt        0    31628   \n",
       "4  CNS_2011_Program.txt        0    24580   \n",
       "5  CNS_2012_Program.txt        0    24793   \n",
       "6  CNS_2013_Program.txt        0    28381   \n",
       "7  CNS_2014_Program.txt        0    28084   \n",
       "8  CNS_2015_Program.txt        0    23909   \n",
       "9  CNS_2016_Program.txt        0    28305   \n",
       "\n",
       "                                          start_sect  \n",
       "0                                             [1456]  \n",
       "1  [1538, 1748, 1969, 2189, 2414, 2647, 2884, 311...  \n",
       "2  [2181, 2395, 2613, 2834, 3076, 3310, 3545, 379...  \n",
       "3  [3236, 3472, 3718, 3974, 4229, 4460, 4694, 495...  \n",
       "4  [3326, 3420, 3667, 3907, 4148, 4394, 4628, 487...  \n",
       "5  [3516, 3610, 3848, 4113, 4353, 4587, 4836, 507...  \n",
       "6  [2881, 3128, 3372, 3626, 3852, 4106, 4348, 459...  \n",
       "7  [3137, 3250, 3505, 3753, 4009, 4253, 4493, 475...  \n",
       "8  [3350, 3588, 3829, 4068, 4322, 4566, 4823, 506...  \n",
       "9  [3593, 3823, 4072, 4313, 4566, 4827, 5087, 533...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cns_frame=pd.DataFrame({'CNS_file':CNS_file,'start_sect':start_sect,'beg_ind':beg_ind,'end_ind':end_ind})\n",
    "cns_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "z=1\n",
    "\n",
    "last_index = 0\n",
    "let_vec = ['A']\n",
    "\n",
    "for j in let_vec:\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= j\n",
    "            cur_abs=i+1\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "\n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                    last_index = cur_section+'%i'%(cur_abs+1)\n",
    "                    print(cur_abs)\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "\n",
    "                except:\n",
    "                    \n",
    "                    print('k = ',k)\n",
    "                    print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                # except ValueError: \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    print('reached else')\n",
    "                    continue\n",
    "\n",
    "                    print(last_index)\n",
    "\n",
    "\n",
    "\n",
    "#                 except ValueError:\n",
    "#                             abs_beg_ind = abs_list.index(last_index)\n",
    "#                             #nxt = cur_section + 1\n",
    "#                             abs_end_ind = abs_list.index('B'+'%i'%z)\n",
    "\n",
    "#                             section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#                             #     print(section_abst)\n",
    "#                             #     print(cur_section+'%i'%(cur_abs+1))\n",
    "#                             #     print(i, abs_beg_ind, abs_end_ind)\n",
    "#                             start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "#                             start_string=last_index #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "#                             whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "#                             title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "#                             title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "#                             title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "#                             length_title_lst=' '.join(title_lst)\n",
    "#                             remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "#                             auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "#                             sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "#                             abst.append(whole_abs)\n",
    "#                             title.append(remove_start_string)\n",
    "#                             #auth.append(title_sect) old wrong way of getting author\n",
    "#                             auth.append(auth_sect)\n",
    "#                             last_index\n",
    "#                     # letter + last index up to B1 \n",
    "#                     # section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract\n",
    "\n",
    "#                             pass\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messing with K outer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "z=1\n",
    "\n",
    "\n",
    "let_vec = ['A','B']\n",
    "\n",
    "for j in range(0,len(let_vec)):\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= let_vec[j]\n",
    "            cur_abs=i\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "            abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "            last_index = cur_section+'%i'%(cur_abs+1)\n",
    "            print(cur_abs)\n",
    "\n",
    "            section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "            #     print(section_abst)\n",
    "            #     print(cur_section+'%i'%(cur_abs+1))\n",
    "            #     print(i, abs_beg_ind, abs_end_ind)\n",
    "            start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "            start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "            whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "            title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "            title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "            title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "            length_title_lst=' '.join(title_lst)\n",
    "            remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "            auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "            sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "            abst.append(whole_abs)\n",
    "            title.append(remove_start_string)\n",
    "            #auth.append(title_sect) old wrong way of getting author\n",
    "            auth.append(auth_sect)\n",
    "            \n",
    "            \n",
    "            last_good = i\n",
    "        except ValueError:\n",
    "            \n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    #print('k = ',k)\n",
    "                    #print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                except:\n",
    "                    #print('except')\n",
    "                    pass\n",
    "\n",
    "       \n",
    "                else:\n",
    "                    #print('reached else')\n",
    "                    pass\n",
    "\n",
    "            #print('last index =',last_index)\n",
    "\n",
    "\n",
    "\n",
    "#                 except ValueError:\n",
    "#                             abs_beg_ind = abs_list.index(last_index)\n",
    "#                             #nxt = cur_section + 1\n",
    "#                             abs_end_ind = abs_list.index('B'+'%i'%z)\n",
    "\n",
    "#                             section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#                             #     print(section_abst)\n",
    "#                             #     print(cur_section+'%i'%(cur_abs+1))\n",
    "#                             #     print(i, abs_beg_ind, abs_end_ind)\n",
    "#                             start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "#                             start_string=last_index #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "#                             whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "#                             title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "#                             title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "#                             title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "#                             length_title_lst=' '.join(title_lst)\n",
    "#                             remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "#                             auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "#                             sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "#                             abst.append(whole_abs)\n",
    "#                             title.append(remove_start_string)\n",
    "#                             #auth.append(title_sect) old wrong way of getting author\n",
    "#                             auth.append(auth_sect)\n",
    "#                             last_index\n",
    "#                     # letter + last index up to B1 \n",
    "#                     # section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract\n",
    "\n",
    "#                             pass\n",
    "        except:\n",
    "            \n",
    "                            abs_beg_ind = abs_list.index(last_index)\n",
    "                            #nxt = cur_section + 1\n",
    "                            abs_end_ind = abs_list.index(let_vec[j+1]+'%i'%z)\n",
    "\n",
    "                            section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                            #     print(section_abst)\n",
    "                            #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                            #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                            start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                            start_string=last_index #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                            whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                            title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                            title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                            title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                            length_title_lst=' '.join(title_lst)\n",
    "                            remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                            auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                            sect_abs.append(last_index)\n",
    "                            abst.append(whole_abs)\n",
    "                            title.append(remove_start_string)\n",
    "                            #auth.append(title_sect) old wrong way of getting author\n",
    "                            auth.append(auth_sect)\n",
    "                            last_index\n",
    "                    # letter + last index up to B1 \n",
    "                    # section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            \n",
    "print(last_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abst</th>\n",
       "      <th>auth</th>\n",
       "      <th>sect_abs</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJEC-  TIVE: Auditory cues have been shown to...</td>\n",
       "      <td>urtis1, Janna K. Comrie1, Anthony Colange1, Su...</td>\n",
       "      <td>A1</td>\n",
       "      <td>EFFECTS OF AUDITORY CUES ON VISUAL ATTENTION:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-initiated sounds elicit an attenuated N1 ...</td>\n",
       "      <td>Jana Timm1, Iria SanMiguel1, Katja Saupe1,  E...</td>\n",
       "      <td>A2</td>\n",
       "      <td>THE N1-SUPPRESSION EFFECT FOR SELF-INITIATED ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the object-based account of audit...</td>\n",
       "      <td>Kristina  Backer1,2, Claude Alain1,2; 1Rotman...</td>\n",
       "      <td>A3</td>\n",
       "      <td>RETRO-CUEING LISTENERS' ATTENTION TO SOUND OB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selective  attention is often described as the...</td>\n",
       "      <td>tian Pavlovic1, Karla D. Ponjavic-Conte1, Matt...</td>\n",
       "      <td>A4</td>\n",
       "      <td>NEURAL CORRELATES OF DISTRACTION IN AUDITORY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Working memory (WM) is a temporary storage sys...</td>\n",
       "      <td>STRACTORS Jessica  Tiffany Jantz1, Ezequiel Mo...</td>\n",
       "      <td>A5</td>\n",
       "      <td>DISTURBING WORKING MEMORY: REHEARSAL, IMAGERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In a crowded sensory environment, organisms mu...</td>\n",
       "      <td>lywy1, Ewan A. Macpherson1, Steven  G. Greenin...</td>\n",
       "      <td>A6</td>\n",
       "      <td>EFFECTS OF EMOTIONAL VALENCE ON THE ‘WHAT’ AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brain imaging data were acquired from two subj...</td>\n",
       "      <td>Kwaku Akrofi1, Jake  Carpenter-Thompson1, Fat...</td>\n",
       "      <td>A7</td>\n",
       "      <td>EFFECTS OF TINNITUS AND HEARING LOSS ON FUNCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Variability in cortical auditory-evoked respon...</td>\n",
       "      <td>Dana Strait1, Nina Kraus1; 1Northwestern Uni...</td>\n",
       "      <td>A8</td>\n",
       "      <td>IMPACTS OF SELECTIVE AUDITORY ATTENTION AND M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recent studies report activity in auditory cor...</td>\n",
       "      <td>Cort Horton1, Michael D'Zmura1, Ramesh Sriniv...</td>\n",
       "      <td>A9</td>\n",
       "      <td>SELECTIVE ATTENTION AND THE NEURAL REPRESENTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When listening to music, we move in synchrony ...</td>\n",
       "      <td>Shu-Jen Kung1,  Ovid Tzeng1,2, Daisy Hung1,3,...</td>\n",
       "      <td>A10</td>\n",
       "      <td>NEUROMAGNETIC CORRELATES OF DYNAMIC ALLOCATIO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The main goal of the study was to explore the ...</td>\n",
       "      <td>Szczepan  Grzybowski1, Miroslaw Wyczesany1; 1...</td>\n",
       "      <td>A11</td>\n",
       "      <td>ERP STUDY OF SELF-REFERENCED MOOD ADJECTIVES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Memory retrieval of guilty self-actions is res...</td>\n",
       "      <td>to Miyauchi1,3, Motoaki Sugiura3, Yukihito Yom...</td>\n",
       "      <td>A12</td>\n",
       "      <td>NEURAL REPRESENTATION OF GUILT IN EPISODIC ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Information encoded in relation to self throug...</td>\n",
       "      <td>ilip Collard1, David J. Turk1; 1  Psychology, ...</td>\n",
       "      <td>A13</td>\n",
       "      <td>OWNERSHIP AND ATTENTION: P300 MODULATION TO S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Self-referential processing has been shown to ...</td>\n",
       "      <td>Drucker1, Christine D. Wilson-  Mendenhall2, ...</td>\n",
       "      <td>A14</td>\n",
       "      <td>NEURAL REPRESENTATIONS OF SELF AND OTHER: BEY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Studies (Alexander et. al 2005; Alexander et. ...</td>\n",
       "      <td>Joel  Alexander1, Ronald Alexander2; 1Western...</td>\n",
       "      <td>A15</td>\n",
       "      <td>P300 AMPLITUDE DIFFERENCES BETWEEN HETEROSEXU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The current study represents a first attempt t...</td>\n",
       "      <td>Lauren 1  Kutcher1,  Steven  Brown1;  McMaste...</td>\n",
       "      <td>A16</td>\n",
       "      <td>THE NEUROSCIENCE OF ACTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>One of the most Alpaugh2,3,  Brownoff3,  Singh...</td>\n",
       "      <td>Esther  Fujiwara1,2, Nick Anthony of Melanie ...</td>\n",
       "      <td>A17</td>\n",
       "      <td>ERP CORRELATES OF THE SELF-POSITIVITY BIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Though several brain areas have been shown to ...</td>\n",
       "      <td>.  Chavez1, Katherine E. Powers1, Todd F. Heat...</td>\n",
       "      <td>A18</td>\n",
       "      <td>STRUCTURAL CONNECTIVITY OF MEDIAL PREFRONTAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Self-knowledge is ipso facto the essential pie...</td>\n",
       "      <td>ONSISTENT WITH EVOLUTIONARY UNDERSTANDING OF T...</td>\n",
       "      <td>A19</td>\n",
       "      <td>NEURAL BASIS OF SELF-CONTINGENCY DETECTION IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It has been established that insular cortex ma...</td>\n",
       "      <td>elder F. Araujo1,2,3, Jonas Kaplan1, Hanna Dam...</td>\n",
       "      <td>A20</td>\n",
       "      <td>INSULA CORTEX ACTIVITY DURING TWO SELF-RELATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Self-knowledge is ipso facto the essential pie...</td>\n",
       "      <td>; 1Laboratoire de Sciences Cognitives et Psych...</td>\n",
       "      <td>A21</td>\n",
       "      <td>FMRI STUDY OF SELF VS. OTHERS’ ATTRIBUTIONS O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Previous studies have reported verbal fluency ...</td>\n",
       "      <td>Ye Seul Shin1, Na Young Shin1,  Joon Hwan Jan...</td>\n",
       "      <td>A22</td>\n",
       "      <td>SWITCHING STRATEGY UNDERLIES VERBAL FLUENCY I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Although much of our behavior is driven by rou...</td>\n",
       "      <td>rlies  E. van Bochove1, Lise Van der Haegen1, ...</td>\n",
       "      <td>A23</td>\n",
       "      <td>BLINK PREDICTS ENHANCED COGNITIVE CONTROL E.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fronto-Parietal regions have been shown to rep...</td>\n",
       "      <td>saf  farooqui1, John Duncan1; 1MRC-Cognition &amp;...</td>\n",
       "      <td>A24</td>\n",
       "      <td>FRONTO-PARIETAL REPRESENTATION OF SEQUENTIAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The human brain is capable of performing numer...</td>\n",
       "      <td>Joseph Dubis1, Joshua Siegel1, Steven  Peters...</td>\n",
       "      <td>A25</td>\n",
       "      <td>THE EFFECT OF RESOURCE-LIMITED AND DATA-LIMIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Behavioural and neural evidence suggests that ...</td>\n",
       "      <td>rly S. Chiew1,  Renaldo Gacad1, Todd S. Braver...</td>\n",
       "      <td>A26</td>\n",
       "      <td>PUPILLOMETRY REVEALS CHANGES IN COGNITIVE CON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Coordination between networks of brain region...</td>\n",
       "      <td>ne L. Baniqued1, Kathy A. Low1, Monica  Fabian...</td>\n",
       "      <td>A27</td>\n",
       "      <td>CROSS-CORRELATION DYNAMICS OF FRONTO-PARIETAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Primary motor cortex  (M1) is critical for mot...</td>\n",
       "      <td>Mooshagian1,2,3, Aysha Keisler1,2, Trelawny Z...</td>\n",
       "      <td>A28</td>\n",
       "      <td>USING TRANSCRANIAL MAGNETIC STIMULATION TO AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Research  of the neural mechanisms underlying ...</td>\n",
       "      <td>Jayde Nail1, Hillary Schwarb1, Zain Sultan1, ...</td>\n",
       "      <td>A29</td>\n",
       "      <td>CORTICAL ACTIVATION CHANGES WITH PERFORMANCE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Anatomical brain structure does not fully pred...</td>\n",
       "      <td>elyn L Begany1,2, Emi M Nomura2,  Mark D'Espos...</td>\n",
       "      <td>A30</td>\n",
       "      <td>PREDICTING THE RESPONSE OF PATIENTS WITH BRAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Recent experiments using a novel search paradi...</td>\n",
       "      <td>rayden Solman1, J Allan Cheyne1, Daniel  Smile...</td>\n",
       "      <td>A76</td>\n",
       "      <td>MOTOR SYSTEMS OUTPACE PERCEPTUAL SYSTEMS DURI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Perceived control over pain, expectancy, and ...</td>\n",
       "      <td>ane Schmidt1, Luka Ruzic2, Daphna Shohamy1, To...</td>\n",
       "      <td>A77</td>\n",
       "      <td>DISENTANGLING THE EFFECTS OF EXPECTANCY, AGEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>The mirror neu-  ron theory of action understa...</td>\n",
       "      <td>Jonathan Venezia1, William Matchin1, Gregory ...</td>\n",
       "      <td>A78</td>\n",
       "      <td>HUMAN \"MIRROR SYSTEM\" CAN BE TRAINED TO RESPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>The present study investigated whether semanti...</td>\n",
       "      <td>Darya Zabelina1, Emmanuel Guzman-Martinez1, L...</td>\n",
       "      <td>A79</td>\n",
       "      <td>SUPPRESSED SEMANTIC INFORMATION ACCELERATES P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>People differ widely from one another in their...</td>\n",
       "      <td>ayan Lu1,2, Jérôme Prado1, Li Liu2,  Qi Dong2,...</td>\n",
       "      <td>A80</td>\n",
       "      <td>CULTURE AND EDUCATION SHAPE THE NEURAL BASES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>In  the intraparietal sulcus (IPS), activation...</td>\n",
       "      <td>Lisa Sprute1, Donna Coch1; 1Dartmouth College</td>\n",
       "      <td>A81</td>\n",
       "      <td>DISTANCE MODULATES INTRAPARIETAL SULCUS ACTIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>The ability to infer causality is a central fe...</td>\n",
       "      <td>dam J. Woods1, Matthew Lehet1, Anjan Chatterje...</td>\n",
       "      <td>A82</td>\n",
       "      <td>THE ROLE OF THE RIGHT PARIETAL CORTEX IN CAUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Objectives: Are individual differences in emot...</td>\n",
       "      <td>, Seung-Hwan Lee1,2, Eun-Ok Moon1, Yoon-Jae Mo...</td>\n",
       "      <td>A83</td>\n",
       "      <td>INDIVIDUAL DIFFERENCES IN CARDIAC VAGAL TONE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Do native speakers of Russian and German use d...</td>\n",
       "      <td>Mariya Kharaman1, Carsten Eulitz1; 1Universit...</td>\n",
       "      <td>A84</td>\n",
       "      <td>DIFFERENT ACOUSTIC CUES ARE USED BY RUSSIANS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Our world presents us with numerical informati...</td>\n",
       "      <td>urtney Lussier1, Jessica F. Cantlon1; 1  Unive...</td>\n",
       "      <td>A85</td>\n",
       "      <td>SEMANTIC PROCESSING OF NUMBER AND SIZE WITHIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>While creativity has been well studied as a st...</td>\n",
       "      <td>Green1, Michael Cohen2, Joseph Kim3, Jeremy Gr...</td>\n",
       "      <td>A86</td>\n",
       "      <td>LOOKING UNDER YOUR THINKING CAP: DELIBERATELY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Spontaneous mental  2  processes (e.g., mind w...</td>\n",
       "      <td>Melissa Ellamil1, Sean Pritchard2, Evan Thomp...</td>\n",
       "      <td>A87</td>\n",
       "      <td>INVESTIGATING THE NEURAL BASIS OF SPONTANEOUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Multiple Sclerosis is a neurodegenerative, inf...</td>\n",
       "      <td>Alisha Janssen1, Amir  Abduljalil2, Aaron Bos...</td>\n",
       "      <td>A88</td>\n",
       "      <td>ALTERED PATTERNS OF NEURAL CONNECTIVITY IN IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Mathematical skills are arguably one of the mo...</td>\n",
       "      <td>Albert Snowball1, Tudor  Popescu1, Jacqueline...</td>\n",
       "      <td>A89</td>\n",
       "      <td>ENHANCING MATHEMATICAL LEARNING: CONCURRENT N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>It has been theorized that the neurotransmitte...</td>\n",
       "      <td>achael Grazioplene1, Colin G DeYoung1, Matthew...</td>\n",
       "      <td>A90</td>\n",
       "      <td>BRAIN STRUCTURE OF CREATIVE EXPLORATION: CAUD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Mounting evidence supports the notion that chi...</td>\n",
       "      <td>Edward Hubbard1, Bruce McCandliss1;  1Vanderb...</td>\n",
       "      <td>A91</td>\n",
       "      <td>EDUCATION-DEPENDENT BRAIN PLASTICITY: FRONTAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Increases in alpha power in the right hemisph...</td>\n",
       "      <td>Polly O'Rourke1, Timothy George1, Alexei Smal...</td>\n",
       "      <td>A92</td>\n",
       "      <td>VERBAL CREATIVITY AND ALPHA: A BRAIN WAVE ENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The horizontal section of the intra-parietal ...</td>\n",
       "      <td>Y. Kallai1, Christian D. Schunn1, Julie  Fiez...</td>\n",
       "      <td>A93</td>\n",
       "      <td>AUTOMATICITY IN PROCESSING OF NUMBERS THAT WE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Previous studies have demonstrated distinct pa...</td>\n",
       "      <td>Carola Salvi1, Steve Franconeri2, Emanuela B...</td>\n",
       "      <td>A94</td>\n",
       "      <td>LOOKING OUTSIDE THE BOX: BLINKS AND EYE MOVEM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Acquiring basic arithmetic skill is a crucial...</td>\n",
       "      <td>Price Gavin1, Mazzocco Michele2,  Ansari Dani...</td>\n",
       "      <td>A95</td>\n",
       "      <td>NEURAL CORRELATES OF MATHEMATICAL COMPETENCE:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Previous research revealed benefit from ?-adre...</td>\n",
       "      <td>Patrick Hecht1, Matthew Will1, Todd  Schachtm...</td>\n",
       "      <td>A96</td>\n",
       "      <td>RODENT MODEL OF THE EFFECT OF BETA-ADRENERGIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Most functional neuroimaging studies use the s...</td>\n",
       "      <td>hristian Battista1, Daniel Ansari1, J  Bruce M...</td>\n",
       "      <td>A97</td>\n",
       "      <td>A CUSTOMIZED ARITHMETIC PROGRAM FOR USE IN FU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Problem solving through insight differs from t...</td>\n",
       "      <td>ephanie Hare1, John Molony1, Sean McCarthy1, K...</td>\n",
       "      <td>A98</td>\n",
       "      <td>INSIGHT FOLLOWS INCUBATION IN THE REMOTE ASSO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>It has been claimed that approximate numerosit...</td>\n",
       "      <td>eng-  Ching Han1, Nai-Shing Yen1, Daniele Didi...</td>\n",
       "      <td>A99</td>\n",
       "      <td>MEMORY UPDATING CAPACITY IS THE BETTER PREDIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Recent theoretical models (Dietrich, 2004; Fla...</td>\n",
       "      <td>z1, Sephira G.  Ryman2, Ranee A. Flores2, Rex ...</td>\n",
       "      <td>A100</td>\n",
       "      <td>GREY MATTER DENSITY IN INDIVIDUALS WITH HIGHE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Based on the twofold model of creativity accor...</td>\n",
       "      <td>Naama  Mayseless1, Simone Shamay-Tsoory1; 1De...</td>\n",
       "      <td>A101</td>\n",
       "      <td>UNDERSTANDING THE NEURAL BASIS OF CREATIVE CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Spreading activation in the brain, a critical ...</td>\n",
       "      <td>IC ACTIVITY Bradley  Aiden Lee1, Kristi String...</td>\n",
       "      <td>A102</td>\n",
       "      <td>RELATIONSHIP BETWEEN CREATIVITY PERFORMANCE, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Often, we must behave  appropriately in circum...</td>\n",
       "      <td>mes Brew1, Michael J. Frank1,2, David Badre1,2...</td>\n",
       "      <td>B0</td>\n",
       "      <td>A103 TRANSFER OF ABSTRACT ACTION RULES DURING ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Previous research has demonstrated age-related...</td>\n",
       "      <td>Tatyana Zhuravleva1, Anna  Haring1, Brittany ...</td>\n",
       "      <td>B1</td>\n",
       "      <td>AGE-RELATED CHANGES IN SELECTIVE ATTENTION IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>A critical mechanism for conserving capacityli...</td>\n",
       "      <td>Brittany Alperin1, Anna Haring1, Tatyana Zhu...</td>\n",
       "      <td>B2</td>\n",
       "      <td>AGE-RELATED CHANGES IN THE PROCESSING OF TO-B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  abst  \\\n",
       "0    OBJEC-  TIVE: Auditory cues have been shown to...   \n",
       "1    Self-initiated sounds elicit an attenuated N1 ...   \n",
       "2    According to the object-based account of audit...   \n",
       "3    Selective  attention is often described as the...   \n",
       "4    Working memory (WM) is a temporary storage sys...   \n",
       "5    In a crowded sensory environment, organisms mu...   \n",
       "6    Brain imaging data were acquired from two subj...   \n",
       "7    Variability in cortical auditory-evoked respon...   \n",
       "8    Recent studies report activity in auditory cor...   \n",
       "9    When listening to music, we move in synchrony ...   \n",
       "10   The main goal of the study was to explore the ...   \n",
       "11   Memory retrieval of guilty self-actions is res...   \n",
       "12   Information encoded in relation to self throug...   \n",
       "13   Self-referential processing has been shown to ...   \n",
       "14   Studies (Alexander et. al 2005; Alexander et. ...   \n",
       "15   The current study represents a first attempt t...   \n",
       "16   One of the most Alpaugh2,3,  Brownoff3,  Singh...   \n",
       "17   Though several brain areas have been shown to ...   \n",
       "18   Self-knowledge is ipso facto the essential pie...   \n",
       "19   It has been established that insular cortex ma...   \n",
       "20   Self-knowledge is ipso facto the essential pie...   \n",
       "21   Previous studies have reported verbal fluency ...   \n",
       "22   Although much of our behavior is driven by rou...   \n",
       "23   Fronto-Parietal regions have been shown to rep...   \n",
       "24   The human brain is capable of performing numer...   \n",
       "25   Behavioural and neural evidence suggests that ...   \n",
       "26    Coordination between networks of brain region...   \n",
       "27   Primary motor cortex  (M1) is critical for mot...   \n",
       "28   Research  of the neural mechanisms underlying ...   \n",
       "29   Anatomical brain structure does not fully pred...   \n",
       "..                                                 ...   \n",
       "75   Recent experiments using a novel search paradi...   \n",
       "76    Perceived control over pain, expectancy, and ...   \n",
       "77   The mirror neu-  ron theory of action understa...   \n",
       "78   The present study investigated whether semanti...   \n",
       "79   People differ widely from one another in their...   \n",
       "80   In  the intraparietal sulcus (IPS), activation...   \n",
       "81   The ability to infer causality is a central fe...   \n",
       "82   Objectives: Are individual differences in emot...   \n",
       "83   Do native speakers of Russian and German use d...   \n",
       "84   Our world presents us with numerical informati...   \n",
       "85   While creativity has been well studied as a st...   \n",
       "86   Spontaneous mental  2  processes (e.g., mind w...   \n",
       "87   Multiple Sclerosis is a neurodegenerative, inf...   \n",
       "88   Mathematical skills are arguably one of the mo...   \n",
       "89   It has been theorized that the neurotransmitte...   \n",
       "90   Mounting evidence supports the notion that chi...   \n",
       "91    Increases in alpha power in the right hemisph...   \n",
       "92    The horizontal section of the intra-parietal ...   \n",
       "93   Previous studies have demonstrated distinct pa...   \n",
       "94    Acquiring basic arithmetic skill is a crucial...   \n",
       "95   Previous research revealed benefit from ?-adre...   \n",
       "96   Most functional neuroimaging studies use the s...   \n",
       "97   Problem solving through insight differs from t...   \n",
       "98   It has been claimed that approximate numerosit...   \n",
       "99   Recent theoretical models (Dietrich, 2004; Fla...   \n",
       "100  Based on the twofold model of creativity accor...   \n",
       "101  Spreading activation in the brain, a critical ...   \n",
       "102  Often, we must behave  appropriately in circum...   \n",
       "103  Previous research has demonstrated age-related...   \n",
       "104  A critical mechanism for conserving capacityli...   \n",
       "\n",
       "                                                  auth sect_abs  \\\n",
       "0    urtis1, Janna K. Comrie1, Anthony Colange1, Su...       A1   \n",
       "1     Jana Timm1, Iria SanMiguel1, Katja Saupe1,  E...       A2   \n",
       "2     Kristina  Backer1,2, Claude Alain1,2; 1Rotman...       A3   \n",
       "3    tian Pavlovic1, Karla D. Ponjavic-Conte1, Matt...       A4   \n",
       "4    STRACTORS Jessica  Tiffany Jantz1, Ezequiel Mo...       A5   \n",
       "5    lywy1, Ewan A. Macpherson1, Steven  G. Greenin...       A6   \n",
       "6     Kwaku Akrofi1, Jake  Carpenter-Thompson1, Fat...       A7   \n",
       "7      Dana Strait1, Nina Kraus1; 1Northwestern Uni...       A8   \n",
       "8     Cort Horton1, Michael D'Zmura1, Ramesh Sriniv...       A9   \n",
       "9     Shu-Jen Kung1,  Ovid Tzeng1,2, Daisy Hung1,3,...      A10   \n",
       "10    Szczepan  Grzybowski1, Miroslaw Wyczesany1; 1...      A11   \n",
       "11   to Miyauchi1,3, Motoaki Sugiura3, Yukihito Yom...      A12   \n",
       "12   ilip Collard1, David J. Turk1; 1  Psychology, ...      A13   \n",
       "13    Drucker1, Christine D. Wilson-  Mendenhall2, ...      A14   \n",
       "14    Joel  Alexander1, Ronald Alexander2; 1Western...      A15   \n",
       "15    Lauren 1  Kutcher1,  Steven  Brown1;  McMaste...      A16   \n",
       "16    Esther  Fujiwara1,2, Nick Anthony of Melanie ...      A17   \n",
       "17   .  Chavez1, Katherine E. Powers1, Todd F. Heat...      A18   \n",
       "18   ONSISTENT WITH EVOLUTIONARY UNDERSTANDING OF T...      A19   \n",
       "19   elder F. Araujo1,2,3, Jonas Kaplan1, Hanna Dam...      A20   \n",
       "20   ; 1Laboratoire de Sciences Cognitives et Psych...      A21   \n",
       "21    Ye Seul Shin1, Na Young Shin1,  Joon Hwan Jan...      A22   \n",
       "22   rlies  E. van Bochove1, Lise Van der Haegen1, ...      A23   \n",
       "23   saf  farooqui1, John Duncan1; 1MRC-Cognition &...      A24   \n",
       "24    Joseph Dubis1, Joshua Siegel1, Steven  Peters...      A25   \n",
       "25   rly S. Chiew1,  Renaldo Gacad1, Todd S. Braver...      A26   \n",
       "26   ne L. Baniqued1, Kathy A. Low1, Monica  Fabian...      A27   \n",
       "27    Mooshagian1,2,3, Aysha Keisler1,2, Trelawny Z...      A28   \n",
       "28    Jayde Nail1, Hillary Schwarb1, Zain Sultan1, ...      A29   \n",
       "29   elyn L Begany1,2, Emi M Nomura2,  Mark D'Espos...      A30   \n",
       "..                                                 ...      ...   \n",
       "75   rayden Solman1, J Allan Cheyne1, Daniel  Smile...      A76   \n",
       "76   ane Schmidt1, Luka Ruzic2, Daphna Shohamy1, To...      A77   \n",
       "77    Jonathan Venezia1, William Matchin1, Gregory ...      A78   \n",
       "78    Darya Zabelina1, Emmanuel Guzman-Martinez1, L...      A79   \n",
       "79   ayan Lu1,2, Jérôme Prado1, Li Liu2,  Qi Dong2,...      A80   \n",
       "80       Lisa Sprute1, Donna Coch1; 1Dartmouth College      A81   \n",
       "81   dam J. Woods1, Matthew Lehet1, Anjan Chatterje...      A82   \n",
       "82   , Seung-Hwan Lee1,2, Eun-Ok Moon1, Yoon-Jae Mo...      A83   \n",
       "83    Mariya Kharaman1, Carsten Eulitz1; 1Universit...      A84   \n",
       "84   urtney Lussier1, Jessica F. Cantlon1; 1  Unive...      A85   \n",
       "85   Green1, Michael Cohen2, Joseph Kim3, Jeremy Gr...      A86   \n",
       "86    Melissa Ellamil1, Sean Pritchard2, Evan Thomp...      A87   \n",
       "87    Alisha Janssen1, Amir  Abduljalil2, Aaron Bos...      A88   \n",
       "88    Albert Snowball1, Tudor  Popescu1, Jacqueline...      A89   \n",
       "89   achael Grazioplene1, Colin G DeYoung1, Matthew...      A90   \n",
       "90    Edward Hubbard1, Bruce McCandliss1;  1Vanderb...      A91   \n",
       "91    Polly O'Rourke1, Timothy George1, Alexei Smal...      A92   \n",
       "92    Y. Kallai1, Christian D. Schunn1, Julie  Fiez...      A93   \n",
       "93     Carola Salvi1, Steve Franconeri2, Emanuela B...      A94   \n",
       "94    Price Gavin1, Mazzocco Michele2,  Ansari Dani...      A95   \n",
       "95    Patrick Hecht1, Matthew Will1, Todd  Schachtm...      A96   \n",
       "96   hristian Battista1, Daniel Ansari1, J  Bruce M...      A97   \n",
       "97   ephanie Hare1, John Molony1, Sean McCarthy1, K...      A98   \n",
       "98   eng-  Ching Han1, Nai-Shing Yen1, Daniele Didi...      A99   \n",
       "99   z1, Sephira G.  Ryman2, Ranee A. Flores2, Rex ...     A100   \n",
       "100   Naama  Mayseless1, Simone Shamay-Tsoory1; 1De...     A101   \n",
       "101  IC ACTIVITY Bradley  Aiden Lee1, Kristi String...     A102   \n",
       "102  mes Brew1, Michael J. Frank1,2, David Badre1,2...       B0   \n",
       "103   Tatyana Zhuravleva1, Anna  Haring1, Brittany ...       B1   \n",
       "104    Brittany Alperin1, Anna Haring1, Tatyana Zhu...       B2   \n",
       "\n",
       "                                                 title  \n",
       "0     EFFECTS OF AUDITORY CUES ON VISUAL ATTENTION:...  \n",
       "1     THE N1-SUPPRESSION EFFECT FOR SELF-INITIATED ...  \n",
       "2     RETRO-CUEING LISTENERS' ATTENTION TO SOUND OB...  \n",
       "3     NEURAL CORRELATES OF DISTRACTION IN AUDITORY ...  \n",
       "4     DISTURBING WORKING MEMORY: REHEARSAL, IMAGERY...  \n",
       "5     EFFECTS OF EMOTIONAL VALENCE ON THE ‘WHAT’ AN...  \n",
       "6     EFFECTS OF TINNITUS AND HEARING LOSS ON FUNCT...  \n",
       "7     IMPACTS OF SELECTIVE AUDITORY ATTENTION AND M...  \n",
       "8     SELECTIVE ATTENTION AND THE NEURAL REPRESENTA...  \n",
       "9     NEUROMAGNETIC CORRELATES OF DYNAMIC ALLOCATIO...  \n",
       "10        ERP STUDY OF SELF-REFERENCED MOOD ADJECTIVES  \n",
       "11    NEURAL REPRESENTATION OF GUILT IN EPISODIC ME...  \n",
       "12    OWNERSHIP AND ATTENTION: P300 MODULATION TO S...  \n",
       "13    NEURAL REPRESENTATIONS OF SELF AND OTHER: BEY...  \n",
       "14    P300 AMPLITUDE DIFFERENCES BETWEEN HETEROSEXU...  \n",
       "15                          THE NEUROSCIENCE OF ACTING  \n",
       "16          ERP CORRELATES OF THE SELF-POSITIVITY BIAS  \n",
       "17    STRUCTURAL CONNECTIVITY OF MEDIAL PREFRONTAL ...  \n",
       "18    NEURAL BASIS OF SELF-CONTINGENCY DETECTION IN...  \n",
       "19    INSULA CORTEX ACTIVITY DURING TWO SELF-RELATE...  \n",
       "20    FMRI STUDY OF SELF VS. OTHERS’ ATTRIBUTIONS O...  \n",
       "21    SWITCHING STRATEGY UNDERLIES VERBAL FLUENCY I...  \n",
       "22        BLINK PREDICTS ENHANCED COGNITIVE CONTROL E.  \n",
       "23    FRONTO-PARIETAL REPRESENTATION OF SEQUENTIAL ...  \n",
       "24    THE EFFECT OF RESOURCE-LIMITED AND DATA-LIMIT...  \n",
       "25    PUPILLOMETRY REVEALS CHANGES IN COGNITIVE CON...  \n",
       "26    CROSS-CORRELATION DYNAMICS OF FRONTO-PARIETAL...  \n",
       "27    USING TRANSCRANIAL MAGNETIC STIMULATION TO AS...  \n",
       "28    CORTICAL ACTIVATION CHANGES WITH PERFORMANCE ...  \n",
       "29    PREDICTING THE RESPONSE OF PATIENTS WITH BRAI...  \n",
       "..                                                 ...  \n",
       "75    MOTOR SYSTEMS OUTPACE PERCEPTUAL SYSTEMS DURI...  \n",
       "76    DISENTANGLING THE EFFECTS OF EXPECTANCY, AGEN...  \n",
       "77    HUMAN \"MIRROR SYSTEM\" CAN BE TRAINED TO RESPO...  \n",
       "78    SUPPRESSED SEMANTIC INFORMATION ACCELERATES P...  \n",
       "79    CULTURE AND EDUCATION SHAPE THE NEURAL BASES ...  \n",
       "80    DISTANCE MODULATES INTRAPARIETAL SULCUS ACTIV...  \n",
       "81    THE ROLE OF THE RIGHT PARIETAL CORTEX IN CAUS...  \n",
       "82    INDIVIDUAL DIFFERENCES IN CARDIAC VAGAL TONE ...  \n",
       "83    DIFFERENT ACOUSTIC CUES ARE USED BY RUSSIANS ...  \n",
       "84    SEMANTIC PROCESSING OF NUMBER AND SIZE WITHIN...  \n",
       "85    LOOKING UNDER YOUR THINKING CAP: DELIBERATELY...  \n",
       "86    INVESTIGATING THE NEURAL BASIS OF SPONTANEOUS...  \n",
       "87    ALTERED PATTERNS OF NEURAL CONNECTIVITY IN IN...  \n",
       "88    ENHANCING MATHEMATICAL LEARNING: CONCURRENT N...  \n",
       "89    BRAIN STRUCTURE OF CREATIVE EXPLORATION: CAUD...  \n",
       "90    EDUCATION-DEPENDENT BRAIN PLASTICITY: FRONTAL...  \n",
       "91    VERBAL CREATIVITY AND ALPHA: A BRAIN WAVE ENT...  \n",
       "92    AUTOMATICITY IN PROCESSING OF NUMBERS THAT WE...  \n",
       "93    LOOKING OUTSIDE THE BOX: BLINKS AND EYE MOVEM...  \n",
       "94    NEURAL CORRELATES OF MATHEMATICAL COMPETENCE:...  \n",
       "95    RODENT MODEL OF THE EFFECT OF BETA-ADRENERGIC...  \n",
       "96    A CUSTOMIZED ARITHMETIC PROGRAM FOR USE IN FU...  \n",
       "97    INSIGHT FOLLOWS INCUBATION IN THE REMOTE ASSO...  \n",
       "98    MEMORY UPDATING CAPACITY IS THE BETTER PREDIC...  \n",
       "99    GREY MATTER DENSITY IN INDIVIDUALS WITH HIGHE...  \n",
       "100   UNDERSTANDING THE NEURAL BASIS OF CREATIVE CO...  \n",
       "101   RELATIONSHIP BETWEEN CREATIVITY PERFORMANCE, ...  \n",
       "102  A103 TRANSFER OF ABSTRACT ACTION RULES DURING ...  \n",
       "103   AGE-RELATED CHANGES IN SELECTIVE ATTENTION IN...  \n",
       "104   AGE-RELATED CHANGES IN THE PROCESSING OF TO-B...  \n",
       "\n",
       "[105 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table[0:105]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The above now works and i get the last index however the section_abst (A103) should be there but i am getting \n",
    "#(B0) instead. I think that it is something weird with the way i use last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "\n",
    "last_index = 0\n",
    "let_vec = ['A','B','C']\n",
    "\n",
    "for j in let_vec:\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= j\n",
    "            cur_abs=i+1\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "\n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                    last_index = cur_section+'%i'%(cur_abs+1)\n",
    "                    #print('index found')\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    \n",
    "                    print('k = ',k)\n",
    "                    print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                except: \n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    pass\n",
    "\n",
    "                print(last_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_end_ind = abs_list.index((cur_section+1'%i'%(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "data_list = data.split('\\n')\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session B')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "#data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session B')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='B'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session C')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session D')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session C')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='C'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session D')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session E')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session D')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='D'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session E')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session F')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session E')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='E'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session F')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session G')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session F')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='F'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session G')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session H')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session G')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='G'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session H')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session I')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session H')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='H'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session I')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Topic Index')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session I')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='I'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        \n",
    "        \n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_table.to_csv(\"CNS_2012_SCRAPED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing another year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[6], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='A'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "data_list = data.split('\\n')\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session B')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[6], 'r')\n",
    "data = file.read()\n",
    "#data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session B')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='B'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session C')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session D')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session C')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='C'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
