{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping abstract information\n",
    "March 4, 2018\n",
    "This notebook scrapes abstract text from:\n",
    "- Proceedings of the Annual Cognitive Science Society meeting archive (html)\n",
    "- Proceedings of Cognitive Neuroscience Society annual meeting (text converted from pdf)\n",
    "\n",
    "Abstracts are then stored in a spreadsheet, containing information such as year, authors, title, and abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_CS(home_url, data_file):\n",
    "    #connect to home page url for that year\n",
    "    CSurl = urllib.request.urlopen(home_url).read()\n",
    "    soup = BeautifulSoup(CSurl, 'html.parser')\n",
    "    all_links = soup.find_all('a', attrs={'href': re.compile(\"papers/*\")})    \n",
    "    year = home_url[-5:-1]    \n",
    "    \n",
    "    # enumerate through all paper links\n",
    "    for link_idx, link in enumerate(all_links):\n",
    "        # get soup from paper url\n",
    "        if home_url not in str(link['href']):\n",
    "            url_text = home_url + str(link['href'])\n",
    "        else:\n",
    "            url_text = str(link['href'])\n",
    "    \n",
    "        url = urllib.request.urlopen(url_text).read()\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "    \n",
    "        # scrape & parse\n",
    "        authors = []\n",
    "        affl = []\n",
    "        title = ' '.join(soup.find_all('h1')[0].text.split())\n",
    "        # exception rule for 2014 abstracts\n",
    "        if '2014' in home_url:            \n",
    "            abstr = ' '.join(soup.find_all('blockquote')[1].text.split())\n",
    "        else:            \n",
    "            abstr = ' '.join(soup.find_all('p', {\"id\": \"abstract\"})[0].text.split())            \n",
    "        \n",
    "        soup.find_all('ul')\n",
    "        for ana in soup.find_all('em'):\n",
    "            affl.append('>'+ana.text)\n",
    "            if '2014' in home_url:\n",
    "                # somebody fucked something up in 2014\n",
    "                authors.append('>' + ana.previous_element.previous_element.split(',')[0])\n",
    "            else:            \n",
    "                authors.append('>' + ana.previous_element.split(',')[0])\n",
    "        \n",
    "        # do some gymnastics to get it into a pandas df and add as a row to CSV\n",
    "        new_row = {'Year': str(year), 'Title': title,'Abstract': abstr,'Authors': ''.join(authors),'Affiliations': ''.join(affl), 'URL': url_text}\n",
    "        df_cur = pd.Series(data=new_row).to_frame().T[['Year','Title','Abstract','Authors','Affiliations','URL']]\n",
    "        df_cur.to_csv(data_file, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all paper links from cogsci conference\n",
    "home_urls = ['https://mindmodeling.org/cogsci2017/',\n",
    "             'https://mindmodeling.org/cogsci2016/',\n",
    "             'https://mindmodeling.org/cogsci2015/',\n",
    "             'https://mindmodeling.org/cogsci2014/',\n",
    "             'https://mindmodeling.org/cogsci2013/',\n",
    "             'https://mindmodeling.org/cogsci2012/',\n",
    "             'https://mindmodeling.org/cogsci2011/',\n",
    "             'https://mindmodeling.org/cogsci2010/']\n",
    "\n",
    "for year in home_urls:\n",
    "    # scrape all\n",
    "    print(year)\n",
    "    scrape_CS(home_url=year, data_file='../data/cogsci_abstracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather CNS abstracts from text to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNS_2007_Program.txt', 'CNS_2008_Program.txt', 'CNS_2009_Program.txt', 'CNS_2010_Program.txt', 'CNS_2011_Program.txt', 'CNS_2012_Program.txt', 'CNS_2013_Program.txt', 'CNS_2014_Program.txt', 'CNS_2015_Program.txt', 'CNS_2016_Program.txt']\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../data/CNS_programs/'\n",
    "os.listdir(data_folder)\n",
    "CNS_files = sorted([f for f in os.listdir(data_folder) if ('CNS' in f) and ('.txt' in f)])[:-1]\n",
    "print(CNS_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#col_names = ['CNS_file','start_sect','beg_ind','end_ind']\n",
    "CNS_file=[]\n",
    "start_sect=[]\n",
    "beg_ind=[]\n",
    "end_ind=[]\n",
    "\n",
    "for i in range(len(CNS_files)):\n",
    "    \n",
    "    CNS_file.append(CNS_files[i])\n",
    "    \n",
    "    #print(CNS_files[i])\n",
    "    file = open(data_folder+CNS_files[i], 'r')\n",
    "    data = file.read()\n",
    "    data_list = data.split('\\n')\n",
    "    abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "    \n",
    "    start_sect.append([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    #print([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    \n",
    "    abs_list = data_list[abs_start:]\n",
    "    poster_beg_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cPoster Session A' == s), None)    \n",
    "    poster_end_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cAuthor Index' == s), None)\n",
    "    \n",
    "    \n",
    "    beg_ind.append(poster_beg_ind)\n",
    "    \n",
    "    end_ind.append(poster_end_ind)\n",
    "    \n",
    "    \n",
    "    #print(poster_beg_ind, poster_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cns_frame=pd.DataFrame({'CNS_file':CNS_file,'start_sect':start_sect,'beg_ind':beg_ind,'end_ind':end_ind})\n",
    "cns_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A44\n",
      "A101\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'A173' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6759cc1a527e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcur_abs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mabs_beg_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_section\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mcur_abs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mabs_end_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_section\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_abs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msection_abst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs_beg_ind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mabs_end_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#entire section including title author and abstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'A173' is not in list"
     ]
    }
   ],
   "source": [
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[9], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    cur_section='A'\n",
    "    cur_abs=i+1\n",
    "    abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#     print(section_abst)\n",
    "#     print(cur_section+'%i'%(cur_abs+1))\n",
    "#     print(i, abs_beg_ind, abs_end_ind)\n",
    "    try:\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "\n",
    "        whole_abs=section_abst[start_abst:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(length_title_lst)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        print(cur_section+'%i'%(cur_abs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_b_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is the bare bones for how the function will run\n",
    "\n",
    "#AKA test weird cases in here bc you can input the specific abstract you want\n",
    "\n",
    "# d = {'sect_abs':[],'abs':[],'title':[],'auth':[]}\n",
    "# Df_2016=pd.DataFrame(data=d)\n",
    "\n",
    "# for i in range(len())\n",
    "cur_section = 'A'\n",
    "#cur_section = 'E '\n",
    "cur_abs = 5\n",
    "abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "start_abst=section_abst.index(\" — \")#index with in the section where we first see this character - which denotes start of abs\n",
    "whole_abs=section_abst[start_abst:len(section_abst)]#the abstract separated from the title and author\n",
    "title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "\n",
    "\n",
    "length_title_lst=' '.join(title_lst)\n",
    "\n",
    "auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "# Df_2016.sect_abs.append(cur_section)\n",
    "# Df_2016.abs.append(whole_abs)\n",
    "# Df_2016.title.append(title_lst)\n",
    "# Df_2016.auth.append(title_sect)\n",
    "#WIP=[word for word in title_sect if not word.islower() and not word.isupper()]#this could possibly be a filter however I intended it to give me mixed case strings which would be the authors.\n",
    "#WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_sect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_title_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abst</th>\n",
       "      <th>auth</th>\n",
       "      <th>sect_abs</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>— Impairments in reciprocal  EXECUTIVE PROCES...</td>\n",
       "      <td>motional behaviours constitute a cornerstone o...</td>\n",
       "      <td>A45</td>\n",
       "      <td>A45 LONGITUDINAL TRAINING IN MEDITATION IS ASS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>— Numerous studies examined the neural correl...</td>\n",
       "      <td>Chiang-shan Li1,2,3, Sheng Zhang1, Sien Hu1; ...</td>\n",
       "      <td>A46</td>\n",
       "      <td>A46 THE NEURAL BASES OF REWARDED “NO ACTION” A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>—  Event-related potentials (ERPs) employed i...</td>\n",
       "      <td>Giorgio Ganis1,2,3, Chun-Wei Hsu1, David Brid...</td>\n",
       "      <td>A47</td>\n",
       "      <td>A47 IS THE FRONTOCENTRAL N2 A RELIABLE INDEX O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>— Previous research conducted  by our team an...</td>\n",
       "      <td>Yi-Yuan Tang1, Rongxiang Tang2; 1Texas Tech  ...</td>\n",
       "      <td>A48</td>\n",
       "      <td>A48 IMAGING BIOMARKER OF SMOKING ADDICTION AND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>— Compatibility effects in selective attentio...</td>\n",
       "      <td>Kerstin Unger1, Rebecca Waugh1, Michael Worde...</td>\n",
       "      <td>A49</td>\n",
       "      <td>A49 EFFECTS OF CONFLICT-DRIVEN ATTENTION ON HI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>— The human capacity to maintain vigilant att...</td>\n",
       "      <td>Anthony Zanesco1, Brandon King1, Katherine Ma...</td>\n",
       "      <td>A50</td>\n",
       "      <td>A50 LONG-TERM MAINTENANCE OF MEDITATION-TRAINI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>— Previous  studies demonstrated decreased mo...</td>\n",
       "      <td>Wim Notebaert1, Carsten Bundt1, Elger Abraham...</td>\n",
       "      <td>A51</td>\n",
       "      <td>A51 REWARD MODULATES PREPARATORY MOTOR CORTEX ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abst  \\\n",
       "43   — Impairments in reciprocal  EXECUTIVE PROCES...   \n",
       "44   — Numerous studies examined the neural correl...   \n",
       "45   —  Event-related potentials (ERPs) employed i...   \n",
       "46   — Previous research conducted  by our team an...   \n",
       "47   — Compatibility effects in selective attentio...   \n",
       "48   — The human capacity to maintain vigilant att...   \n",
       "49   — Previous  studies demonstrated decreased mo...   \n",
       "\n",
       "                                                 auth sect_abs  \\\n",
       "43  motional behaviours constitute a cornerstone o...      A45   \n",
       "44   Chiang-shan Li1,2,3, Sheng Zhang1, Sien Hu1; ...      A46   \n",
       "45   Giorgio Ganis1,2,3, Chun-Wei Hsu1, David Brid...      A47   \n",
       "46   Yi-Yuan Tang1, Rongxiang Tang2; 1Texas Tech  ...      A48   \n",
       "47   Kerstin Unger1, Rebecca Waugh1, Michael Worde...      A49   \n",
       "48   Anthony Zanesco1, Brandon King1, Katherine Ma...      A50   \n",
       "49   Wim Notebaert1, Carsten Bundt1, Elger Abraham...      A51   \n",
       "\n",
       "                                                title  \n",
       "43  A45 LONGITUDINAL TRAINING IN MEDITATION IS ASS...  \n",
       "44  A46 THE NEURAL BASES OF REWARDED “NO ACTION” A...  \n",
       "45  A47 IS THE FRONTOCENTRAL N2 A RELIABLE INDEX O...  \n",
       "46  A48 IMAGING BIOMARKER OF SMOKING ADDICTION AND...  \n",
       "47  A49 EFFECTS OF CONFLICT-DRIVEN ATTENTION ON HI...  \n",
       "48  A50 LONG-TERM MAINTENANCE OF MEDITATION-TRAINI...  \n",
       "49  A51 REWARD MODULATES PREPARATORY MOTOR CORTEX ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table[43:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for table\n",
    "-abst seems fine\n",
    "\n",
    "-auth\n",
    "    want to take out the A# and lowercase it and only include the actual author\n",
    "\n",
    "-sect_abs\n",
    "    want to add number to the A\n",
    "\n",
    "-title\n",
    "    want to join and then lower and drop the A#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(CNS_files)):\n",
    "for i in range(1):\n",
    "    file = open(data_folder+CNS_files[9], 'r')\n",
    "    print(CNS_files[9])\n",
    "    data = file.read()\n",
    "    data_list = data.split('\\n')\n",
    "    poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "    if '\\x0cPoster Topic Index' in data_list:\n",
    "        poster_end_ind = data_list.index('\\x0cPoster Topic Index')\n",
    "    else:\n",
    "        poster_end_ind = data_list.index('\\x0cAuthor Index')\n",
    "\n",
    "    #print(poster_beg_ind, poster_end_ind)\n",
    "    ' '.join(abs_list[abs_beg_ind:abs_end_ind])\n",
    "    #print(data_list[poster_beg_ind:poster_end_ind])\n",
    "    #print(poster_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(CNS_files[1])\n",
    "file = open(data_folder+CNS_files[9], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "print(data_list.index('\\x0cPoster Session A'))\n",
    "data_list[data_list.index('\\x0cPoster Session H'):]\n",
    "' '.join(data_list[data_list.index('\\x0cPoster Session H'):])\n",
    "#splitiing the data on the new line and then concatinating the list it makes with space and .join\n",
    "#Good starting point\n",
    "#try to follow format for the other csv that is sompleted this one is not completed\n",
    "#do Not do 2017 because they do not have the abstracts, however if i can finish looping through all exacpt 2017\n",
    "#then go back to 2017 and do the talks\n",
    "\n",
    "#of the ones in CNS to do, they all seem to follow this format of having for example H1 and then the title of the \n",
    "#abstract and that is in all caps and then that is followed by the authors and they all have numbers \n",
    "#and then the abstract startsso there are some nice delimeters in there that i can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_sess(abs_list, poster_beg_ind):\n",
    "    # find the number of poster sessions from the schedule section\n",
    "    sched = abs_list[:poster_beg_ind]\n",
    "    for ind, sess in enumerate(string.ascii_uppercase):\n",
    "        if sess not in sched:  \n",
    "            return string.ascii_uppercase[:ind]\n",
    "\n",
    "sess = find_num_sess(abs_list, poster_beg_ind)\n",
    "sess\n",
    "#'Poster Session ' + sess[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[9], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    cur_section='A'\n",
    "    cur_abs=i+1\n",
    "    abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#     print(section_abst)\n",
    "#     print(cur_section+'%i'%(cur_abs+1))\n",
    "#     print(i, abs_beg_ind, abs_end_ind)\n",
    "    try:\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "\n",
    "        whole_abs=section_abst[start_abst:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(length_title_lst)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        print(cur_section+'%i'%(cur_abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'A4643' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a88d2a811544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mji\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mabs_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mji\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mabs_beg_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mji\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mabs_end_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mji\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'A4643' is not in list"
     ]
    }
   ],
   "source": [
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session F')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "#a_b_range=list(a_b_range)\n",
    "alpha=['A','B','C','D','E','F']\n",
    "file = open(data_folder+CNS_files[9], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "\n",
    "#messing with letter iterations\n",
    "\n",
    "big_range=letter_end_ind-letter_start_ind\n",
    "\n",
    "\n",
    "#for cur_section in \n",
    "for letter in alpha:\n",
    "    for i in range(big_range):\n",
    "        #cur_section=alpha[letter]\n",
    "        cur_abs=i+1\n",
    "#         abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "#         abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "        abs_beg_ind = abs_list.index(letter+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(letter+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        try:\n",
    "            start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "\n",
    "            whole_abs=section_abst[start_abst:len(section_abst)]#the abstract separated from the title and author\n",
    "            title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "            title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "            title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "            length_title_lst=' '.join(title_lst)\n",
    "            auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "            sect_abs.append(letter+'%i'%cur_abs)\n",
    "            abst.append(whole_abs)\n",
    "            title.append(length_title_lst)\n",
    "            #auth.append(title_sect) old wrong way of getting author\n",
    "            auth.append(auth_sect)\n",
    "        except :\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-f74fc9d45f81>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-f74fc9d45f81>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "#a_b_range=list(a_b_range)\n",
    "alpha=['A','B','C','D','E','F']\n",
    "file = open(data_folder+CNS_files[9], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "\n",
    "#messing with letter iterations\n",
    "\n",
    "big_range=letter_end_ind-letter_start_ind\n",
    "\n",
    "\n",
    "#for cur_section in \n",
    "\n",
    "for i in range(big_range):\n",
    "    try:\n",
    "        cur_section='A'\n",
    "        cur_abs=i+1\n",
    "#         abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "#         abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#     print(section_abst)\n",
    "#     print(cur_section+'%i'%(cur_abs+1))\n",
    "#     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "\n",
    "        whole_abs=section_abst[start_abst:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(length_title_lst)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    \n",
    "    except :\n",
    "        print(\"next letter\")\n",
    "        except:\n",
    "            for i in range(big_range):\n",
    "                cur_section='B'\n",
    "                cur_abs=i+1\n",
    "        #         abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        #         abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "                abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "                section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "        #     print(section_abst)\n",
    "        #     print(cur_section+'%i'%(cur_abs+1))\n",
    "        #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "\n",
    "                whole_abs=section_abst[start_abst:len(section_abst)]#the abstract separated from the title and author\n",
    "                title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                length_title_lst=' '.join(title_lst)\n",
    "                auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                abst.append(whole_abs)\n",
    "                title.append(length_title_lst)\n",
    "                #auth.append(title_sect) old wrong way of getting author\n",
    "                auth.append(auth_sect)\n",
    "                except:\n",
    "                    print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abst</th>\n",
       "      <th>auth</th>\n",
       "      <th>sect_abs</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [abst, auth, sect_abs, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_end_ind-letter_start_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_beg_ind,abs_end_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playing with alphabet loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=['A','B','C','D','E','F','G','H','I']\n",
    "number=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huh=[]\n",
    "for letter in alpha:\n",
    "    for i in range(10):\n",
    "        h=i+1\n",
    "        you=letter+'%i'%h\n",
    "        huh.append(you)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so the below stuff works off of what you can do with the whole_abs cell a couple above. I Think the problem\n",
    "# with the below cell is that a it might not work on the same priciples that the above one does, like \n",
    "# maybe it is working with one simple block\n",
    "# or B i think that abs_list needs to be initalized to make it so I am only looking at CNS 2016\n",
    "# once you can make sure you are only working with CNS 2016 then I think that the below should work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cns_frame=pd.DataFrame({'CNS_file':CNS_file,'start_sect':start_sect,'beg_ind':beg_ind,'end_ind':end_ind})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "so lets get this to work at least for the A's and then we can worry about moving to the next letter.\n",
    "so im thinking we do a while loop saying while cur_section = A: current abstract = i initialize \n",
    "    i to be one outside then have i increment inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cns_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_section= ['']\n",
    "alpha= string.ascii_uppercase\n",
    "alpha_list=[]\n",
    "for i in alpha:\n",
    "    alpha_list.append(i)\n",
    "alpha_list\n",
    "for j in range(len(alpha_list)):\n",
    "    while cur_section == alpha_list[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cur_section letter + curabs number in abs_list.index(cur_section+'%i'%cur_abs):\n",
    "    do all this appending stuff of the abstract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(s,value):\n",
    "    total=0\n",
    "    for elem in s:\n",
    "        if elem== value:\n",
    "            total=total+1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha= string.ascii_uppercase\n",
    "alpha_list=[]\n",
    "for i in alpha:\n",
    "    alpha_list.append(i)\n",
    "alpha_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#d = {'sect+abs':[cur_section],'abs':[whole_abs],'title':[title_lst],'auth':[title_sect]}\n",
    "d = {'sect+abs':[],'abs':[],'title':[],'auth':[]}\n",
    "Df_2016=pd.DataFrame(data=d)\n",
    "Df_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(columns=['Year','Title','Abstract','Author',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[item for item in title_test_1 if item not in title_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_lst=' '.join(title_lst)\n",
    "title_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_section = 'A'\n",
    "#cur_section = 'E '\n",
    "cur_abs = 129\n",
    "abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "#section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])\n",
    "this_sec=abs_list[abs_beg_ind:abs_end_ind]\n",
    "#title_start=len(abs_list[abs_beg_ind])\n",
    "this_sec[this_sec.isupper]\n",
    "#abs_list[title_start:\n",
    "#whole_title=abs_list[title_start:\n",
    "#want all the string until I hit a lower case string\n",
    "#section_abst\n",
    "# start_abst=section_abst.index(\" — \")\n",
    "# whole_abs=section_abst[start_abst:]\n",
    "# whole_abs\n",
    "#abs_list[abs_beg_ind:abs_end_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(CNS_files)):\n",
    "file = open(data_folder+CNS_files[0], 'r')\n",
    "print(CNS_files[0])\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "#abs_start_del= data_list.iloc[\" - \"]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "test_a= data_list[poster_beg_ind:poster_beg_ind+10]\n",
    "# abs_start_del = data_list.index('\\x0c— ')\n",
    "# if '\\x0cPoster Topic Index' in data_list:\n",
    "#     poster_end_ind = data_list.index('\\x0cPoster Topic Index')\n",
    "# else:\n",
    "#     poster_end_ind = data_list.index('\\x0cAuthor Index')\n",
    "\n",
    "#     #print(poster_beg_ind, poster_end_ind)\n",
    "#     print(data_list[poster_beg_ind:poster_beg_ind+7])\n",
    "#     print('---')\n",
    "#     print(data_list[poster_beg_ind:abs_start_del])\n",
    "#test_a\n",
    "\n",
    "# if testing.find(\" — \") == -1:\n",
    "#     print (\"No ' — ' here!\")\n",
    "# else:\n",
    "#     print (\"Found 'is' in the string.\")\n",
    "\n",
    "ahhh= testing.index(\" — \")\n",
    "ahhh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNS_files[0])\n",
    "file = open(data_folder+CNS_files[0], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "print(data_list.index('\\x0cPoster Session A'))\n",
    "data_list[data_list.index('\\x0cPoster Session A'):poster_beg_ind+15]\n",
    "testing=' '.join(data_list[data_list.index('\\x0cPoster Session A'):poster_beg_ind+15])\n",
    "# if testing.find(\" — \") == -1: #okay so this is the delimeter for the start of the abstract\n",
    "#     print (\"No ' — ' here!\")\n",
    "# else:\n",
    "#     print (\"Found 'is' in the string.\")#this returns bc this is in this chunk of string. \n",
    "#so now I want to do something where it groups each abstract section from some point to s\n",
    "\n",
    "ahhh= testing.index(\" — \")\n",
    "ahhh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stings='A0 A1 A2 A3 A4 A5 A6'\n",
    "j=[0,1,2,3,4,5,6]\n",
    "for i in range(len(strings)):\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
