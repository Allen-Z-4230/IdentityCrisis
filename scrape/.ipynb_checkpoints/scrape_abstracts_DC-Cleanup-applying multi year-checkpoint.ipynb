{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping abstract information\n",
    "March 4, 2018\n",
    "This notebook scrapes abstract text from:\n",
    "- Proceedings of the Annual Cognitive Science Society meeting archive (html)\n",
    "- Proceedings of Cognitive Neuroscience Society annual meeting (text converted from pdf)\n",
    "\n",
    "Abstracts are then stored in a spreadsheet, containing information such as year, authors, title, and abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_CS(home_url, data_file):\n",
    "    #connect to home page url for that year\n",
    "    CSurl = urllib.request.urlopen(home_url).read()\n",
    "    soup = BeautifulSoup(CSurl, 'html.parser')\n",
    "    all_links = soup.find_all('a', attrs={'href': re.compile(\"papers/*\")})    \n",
    "    year = home_url[-5:-1]    \n",
    "    \n",
    "    # enumerate through all paper links\n",
    "    for link_idx, link in enumerate(all_links):\n",
    "        # get soup from paper url\n",
    "        if home_url not in str(link['href']):\n",
    "            url_text = home_url + str(link['href'])\n",
    "        else:\n",
    "            url_text = str(link['href'])\n",
    "    \n",
    "        url = urllib.request.urlopen(url_text).read()\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "    \n",
    "        # scrape & parse\n",
    "        authors = []\n",
    "        affl = []\n",
    "        title = ' '.join(soup.find_all('h1')[0].text.split())\n",
    "        # exception rule for 2014 abstracts\n",
    "        if '2014' in home_url:            \n",
    "            abstr = ' '.join(soup.find_all('blockquote')[1].text.split())\n",
    "        else:            \n",
    "            abstr = ' '.join(soup.find_all('p', {\"id\": \"abstract\"})[0].text.split())            \n",
    "        \n",
    "        soup.find_all('ul')\n",
    "        for ana in soup.find_all('em'):\n",
    "            affl.append('>'+ana.text)\n",
    "            if '2014' in home_url:\n",
    "                # somebody fucked something up in 2014\n",
    "                authors.append('>' + ana.previous_element.previous_element.split(',')[0])\n",
    "            else:            \n",
    "                authors.append('>' + ana.previous_element.split(',')[0])\n",
    "        \n",
    "        # do some gymnastics to get it into a pandas df and add as a row to CSV\n",
    "        new_row = {'Year': str(year), 'Title': title,'Abstract': abstr,'Authors': ''.join(authors),'Affiliations': ''.join(affl), 'URL': url_text}\n",
    "        df_cur = pd.Series(data=new_row).to_frame().T[['Year','Title','Abstract','Authors','Affiliations','URL']]\n",
    "        df_cur.to_csv(data_file, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all paper links from cogsci conference\n",
    "home_urls = ['https://mindmodeling.org/cogsci2017/',\n",
    "             'https://mindmodeling.org/cogsci2016/',\n",
    "             'https://mindmodeling.org/cogsci2015/',\n",
    "             'https://mindmodeling.org/cogsci2014/',\n",
    "             'https://mindmodeling.org/cogsci2013/',\n",
    "             'https://mindmodeling.org/cogsci2012/',\n",
    "             'https://mindmodeling.org/cogsci2011/',\n",
    "             'https://mindmodeling.org/cogsci2010/']\n",
    "\n",
    "for year in home_urls:\n",
    "    # scrape all\n",
    "    print(year)\n",
    "    scrape_CS(home_url=year, data_file='../data/cogsci_abstracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather CNS abstracts from text to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNS_2007_Program.txt', 'CNS_2008_Program.txt', 'CNS_2009_Program.txt', 'CNS_2010_Program.txt', 'CNS_2011_Program.txt', 'CNS_2012_Program.txt', 'CNS_2013_Program.txt', 'CNS_2014_Program.txt', 'CNS_2015_Program.txt', 'CNS_2016_Program.txt']\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../data/CNS_programs/'\n",
    "os.listdir(data_folder)\n",
    "CNS_files = sorted([f for f in os.listdir(data_folder) if ('CNS' in f) and ('.txt' in f)])[:-1]\n",
    "print(CNS_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#col_names = ['CNS_file','start_sect','beg_ind','end_ind']\n",
    "\n",
    "#reffering to the abs_list problem encountered in journal on 8/2/2018. I think this needs to be on the outside of the loop so that it can catch each abs_list year change\n",
    "\n",
    "\n",
    "CNS_file=[]\n",
    "start_sect=[]\n",
    "beg_ind=[]\n",
    "end_ind=[]\n",
    "\n",
    "for i in range(len(CNS_files)):\n",
    "    \n",
    "    CNS_file.append(CNS_files[i])\n",
    "    \n",
    "    #print(CNS_files[i])\n",
    "    file = open(data_folder+CNS_files[i], 'r')#the 8 is supposed to be \"i\" but I think that it is grabbing the last one and using that to make abs list each time \n",
    "    data = file.read()\n",
    "    data_list = data.split('\\n')\n",
    "    abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "    \n",
    "    start_sect.append([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    #print([ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d])\n",
    "    \n",
    "    abs_list = data_list[abs_start:]\n",
    "    poster_beg_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cPoster Session A' == s), None)    \n",
    "    poster_end_ind = next((ind for ind,s in enumerate(abs_list) if '\\x0cAuthor Index' == s), None)\n",
    "    \n",
    "    \n",
    "    beg_ind.append(poster_beg_ind)\n",
    "    \n",
    "    end_ind.append(poster_end_ind)\n",
    "    \n",
    "    \n",
    "    #print(poster_beg_ind, poster_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNS_file</th>\n",
       "      <th>beg_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>start_sect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNS_2007_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>29493</td>\n",
       "      <td>[1456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNS_2008_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>30363</td>\n",
       "      <td>[1538, 1748, 1969, 2189, 2414, 2647, 2884, 311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNS_2009_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>23882</td>\n",
       "      <td>[2181, 2395, 2613, 2834, 3076, 3310, 3545, 379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNS_2010_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>31628</td>\n",
       "      <td>[3236, 3472, 3718, 3974, 4229, 4460, 4694, 495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNS_2011_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>24580</td>\n",
       "      <td>[3326, 3420, 3667, 3907, 4148, 4394, 4628, 487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNS_2012_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>24793</td>\n",
       "      <td>[3516, 3610, 3848, 4113, 4353, 4587, 4836, 507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNS_2013_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28381</td>\n",
       "      <td>[2881, 3128, 3372, 3626, 3852, 4106, 4348, 459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNS_2014_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28084</td>\n",
       "      <td>[3137, 3250, 3505, 3753, 4009, 4253, 4493, 475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNS_2015_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>23909</td>\n",
       "      <td>[3350, 3588, 3829, 4068, 4322, 4566, 4823, 506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNS_2016_Program.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>28305</td>\n",
       "      <td>[3593, 3823, 4072, 4313, 4566, 4827, 5087, 533...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CNS_file  beg_ind  end_ind  \\\n",
       "0  CNS_2007_Program.txt        0    29493   \n",
       "1  CNS_2008_Program.txt        0    30363   \n",
       "2  CNS_2009_Program.txt        0    23882   \n",
       "3  CNS_2010_Program.txt        0    31628   \n",
       "4  CNS_2011_Program.txt        0    24580   \n",
       "5  CNS_2012_Program.txt        0    24793   \n",
       "6  CNS_2013_Program.txt        0    28381   \n",
       "7  CNS_2014_Program.txt        0    28084   \n",
       "8  CNS_2015_Program.txt        0    23909   \n",
       "9  CNS_2016_Program.txt        0    28305   \n",
       "\n",
       "                                          start_sect  \n",
       "0                                             [1456]  \n",
       "1  [1538, 1748, 1969, 2189, 2414, 2647, 2884, 311...  \n",
       "2  [2181, 2395, 2613, 2834, 3076, 3310, 3545, 379...  \n",
       "3  [3236, 3472, 3718, 3974, 4229, 4460, 4694, 495...  \n",
       "4  [3326, 3420, 3667, 3907, 4148, 4394, 4628, 487...  \n",
       "5  [3516, 3610, 3848, 4113, 4353, 4587, 4836, 507...  \n",
       "6  [2881, 3128, 3372, 3626, 3852, 4106, 4348, 459...  \n",
       "7  [3137, 3250, 3505, 3753, 4009, 4253, 4493, 475...  \n",
       "8  [3350, 3588, 3829, 4068, 4322, 4566, 4823, 506...  \n",
       "9  [3593, 3823, 4072, 4313, 4566, 4827, 5087, 533...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cns_frame=pd.DataFrame({'CNS_file':CNS_file,'start_sect':start_sect,'beg_ind':beg_ind,'end_ind':end_ind})\n",
    "cns_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "k =  2\n",
      "A22\n",
      "We hit this point\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "k =  2\n",
      "A49\n",
      "We hit this point\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "k =  2\n",
      "A76\n",
      "We hit this point\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "k =  2\n",
      "A105\n",
      "B\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "k =  2\n",
      "B7\n",
      "6\n",
      "k =  2\n",
      "B8\n",
      "7\n",
      "k =  2\n",
      "B9\n",
      "We hit this point\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "k =  2\n",
      "B17\n",
      "We hit this point\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "k =  2\n",
      "B75\n",
      "C\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "k =  2\n",
      "C26\n",
      "We hit this point\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "k =  2\n",
      "C40\n",
      "We hit this point\n",
      "40\n",
      "41\n",
      "42\n",
      "k =  2\n",
      "C44\n",
      "k =  2\n",
      "C45\n",
      "We hit this point\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "k =  2\n",
      "C86\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "k =  2\n",
      "C114\n"
     ]
    }
   ],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "z=1\n",
    "\n",
    "last_index = 0\n",
    "let_vec = ['A','B','C']\n",
    "\n",
    "for j in let_vec:\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= j\n",
    "            cur_abs=i\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "\n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                    last_index = cur_section+'%i'%(cur_abs+1)\n",
    "                    print(cur_abs)\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    \n",
    "                    print('k = ',k)\n",
    "                    print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    print('We hit this point')\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                # except ValueError: \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    print('reached else')\n",
    "                    continue\n",
    "\n",
    "                print(last_index)\n",
    "\n",
    "\n",
    "\n",
    "#                 except ValueError:\n",
    "#                             abs_beg_ind = abs_list.index(last_index)\n",
    "#                             #nxt = cur_section + 1\n",
    "#                             abs_end_ind = abs_list.index('B'+'%i'%z)\n",
    "\n",
    "#                             section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "#                             #     print(section_abst)\n",
    "#                             #     print(cur_section+'%i'%(cur_abs+1))\n",
    "#                             #     print(i, abs_beg_ind, abs_end_ind)\n",
    "#                             start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "#                             start_string=last_index #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "#                             whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "#                             title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "#                             title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "#                             title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "#                             length_title_lst=' '.join(title_lst)\n",
    "#                             remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "#                             auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "#                             sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "#                             abst.append(whole_abs)\n",
    "#                             title.append(remove_start_string)\n",
    "#                             #auth.append(title_sect) old wrong way of getting author\n",
    "#                             auth.append(auth_sect)\n",
    "#                             last_index\n",
    "#                     # letter + last index up to B1 \n",
    "#                     # section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract\n",
    "\n",
    "#                             pass\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abst</th>\n",
       "      <th>auth</th>\n",
       "      <th>sect_abs</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJEC-  TIVE: Auditory cues have been shown to...</td>\n",
       "      <td>urtis1, Janna K. Comrie1, Anthony Colange1, Su...</td>\n",
       "      <td>A1</td>\n",
       "      <td>EFFECTS OF AUDITORY CUES ON VISUAL ATTENTION:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-initiated sounds elicit an attenuated N1 ...</td>\n",
       "      <td>Jana Timm1, Iria SanMiguel1, Katja Saupe1,  E...</td>\n",
       "      <td>A2</td>\n",
       "      <td>THE N1-SUPPRESSION EFFECT FOR SELF-INITIATED ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the object-based account of audit...</td>\n",
       "      <td>Kristina  Backer1,2, Claude Alain1,2; 1Rotman...</td>\n",
       "      <td>A3</td>\n",
       "      <td>RETRO-CUEING LISTENERS' ATTENTION TO SOUND OB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selective  attention is often described as the...</td>\n",
       "      <td>tian Pavlovic1, Karla D. Ponjavic-Conte1, Matt...</td>\n",
       "      <td>A4</td>\n",
       "      <td>NEURAL CORRELATES OF DISTRACTION IN AUDITORY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Working memory (WM) is a temporary storage sys...</td>\n",
       "      <td>STRACTORS Jessica  Tiffany Jantz1, Ezequiel Mo...</td>\n",
       "      <td>A5</td>\n",
       "      <td>DISTURBING WORKING MEMORY: REHEARSAL, IMAGERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In a crowded sensory environment, organisms mu...</td>\n",
       "      <td>lywy1, Ewan A. Macpherson1, Steven  G. Greenin...</td>\n",
       "      <td>A6</td>\n",
       "      <td>EFFECTS OF EMOTIONAL VALENCE ON THE ‘WHAT’ AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brain imaging data were acquired from two subj...</td>\n",
       "      <td>Kwaku Akrofi1, Jake  Carpenter-Thompson1, Fat...</td>\n",
       "      <td>A7</td>\n",
       "      <td>EFFECTS OF TINNITUS AND HEARING LOSS ON FUNCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Variability in cortical auditory-evoked respon...</td>\n",
       "      <td>Dana Strait1, Nina Kraus1; 1Northwestern Uni...</td>\n",
       "      <td>A8</td>\n",
       "      <td>IMPACTS OF SELECTIVE AUDITORY ATTENTION AND M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recent studies report activity in auditory cor...</td>\n",
       "      <td>Cort Horton1, Michael D'Zmura1, Ramesh Sriniv...</td>\n",
       "      <td>A9</td>\n",
       "      <td>SELECTIVE ATTENTION AND THE NEURAL REPRESENTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When listening to music, we move in synchrony ...</td>\n",
       "      <td>Shu-Jen Kung1,  Ovid Tzeng1,2, Daisy Hung1,3,...</td>\n",
       "      <td>A10</td>\n",
       "      <td>NEUROMAGNETIC CORRELATES OF DYNAMIC ALLOCATIO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The main goal of the study was to explore the ...</td>\n",
       "      <td>Szczepan  Grzybowski1, Miroslaw Wyczesany1; 1...</td>\n",
       "      <td>A11</td>\n",
       "      <td>ERP STUDY OF SELF-REFERENCED MOOD ADJECTIVES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Memory retrieval of guilty self-actions is res...</td>\n",
       "      <td>to Miyauchi1,3, Motoaki Sugiura3, Yukihito Yom...</td>\n",
       "      <td>A12</td>\n",
       "      <td>NEURAL REPRESENTATION OF GUILT IN EPISODIC ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Information encoded in relation to self throug...</td>\n",
       "      <td>ilip Collard1, David J. Turk1; 1  Psychology, ...</td>\n",
       "      <td>A13</td>\n",
       "      <td>OWNERSHIP AND ATTENTION: P300 MODULATION TO S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Self-referential processing has been shown to ...</td>\n",
       "      <td>Drucker1, Christine D. Wilson-  Mendenhall2, ...</td>\n",
       "      <td>A14</td>\n",
       "      <td>NEURAL REPRESENTATIONS OF SELF AND OTHER: BEY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Studies (Alexander et. al 2005; Alexander et. ...</td>\n",
       "      <td>Joel  Alexander1, Ronald Alexander2; 1Western...</td>\n",
       "      <td>A15</td>\n",
       "      <td>P300 AMPLITUDE DIFFERENCES BETWEEN HETEROSEXU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The current study represents a first attempt t...</td>\n",
       "      <td>Lauren 1  Kutcher1,  Steven  Brown1;  McMaste...</td>\n",
       "      <td>A16</td>\n",
       "      <td>THE NEUROSCIENCE OF ACTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>One of the most Alpaugh2,3,  Brownoff3,  Singh...</td>\n",
       "      <td>Esther  Fujiwara1,2, Nick Anthony of Melanie ...</td>\n",
       "      <td>A17</td>\n",
       "      <td>ERP CORRELATES OF THE SELF-POSITIVITY BIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Though several brain areas have been shown to ...</td>\n",
       "      <td>.  Chavez1, Katherine E. Powers1, Todd F. Heat...</td>\n",
       "      <td>A18</td>\n",
       "      <td>STRUCTURAL CONNECTIVITY OF MEDIAL PREFRONTAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Self-knowledge is ipso facto the essential pie...</td>\n",
       "      <td>ONSISTENT WITH EVOLUTIONARY UNDERSTANDING OF T...</td>\n",
       "      <td>A19</td>\n",
       "      <td>NEURAL BASIS OF SELF-CONTINGENCY DETECTION IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It has been established that insular cortex ma...</td>\n",
       "      <td>elder F. Araujo1,2,3, Jonas Kaplan1, Hanna Dam...</td>\n",
       "      <td>A20</td>\n",
       "      <td>INSULA CORTEX ACTIVITY DURING TWO SELF-RELATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Self-knowledge is ipso facto the essential pie...</td>\n",
       "      <td>; 1Laboratoire de Sciences Cognitives et Psych...</td>\n",
       "      <td>A21</td>\n",
       "      <td>FMRI STUDY OF SELF VS. OTHERS’ ATTRIBUTIONS O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Previous studies have reported verbal fluency ...</td>\n",
       "      <td>Ye Seul Shin1, Na Young Shin1,  Joon Hwan Jan...</td>\n",
       "      <td>A22</td>\n",
       "      <td>SWITCHING STRATEGY UNDERLIES VERBAL FLUENCY I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Although much of our behavior is driven by rou...</td>\n",
       "      <td>rlies  E. van Bochove1, Lise Van der Haegen1, ...</td>\n",
       "      <td>A23</td>\n",
       "      <td>BLINK PREDICTS ENHANCED COGNITIVE CONTROL E.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fronto-Parietal regions have been shown to rep...</td>\n",
       "      <td>saf  farooqui1, John Duncan1; 1MRC-Cognition &amp;...</td>\n",
       "      <td>A24</td>\n",
       "      <td>FRONTO-PARIETAL REPRESENTATION OF SEQUENTIAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The human brain is capable of performing numer...</td>\n",
       "      <td>Joseph Dubis1, Joshua Siegel1, Steven  Peters...</td>\n",
       "      <td>A25</td>\n",
       "      <td>THE EFFECT OF RESOURCE-LIMITED AND DATA-LIMIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Behavioural and neural evidence suggests that ...</td>\n",
       "      <td>rly S. Chiew1,  Renaldo Gacad1, Todd S. Braver...</td>\n",
       "      <td>A26</td>\n",
       "      <td>PUPILLOMETRY REVEALS CHANGES IN COGNITIVE CON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Coordination between networks of brain region...</td>\n",
       "      <td>ne L. Baniqued1, Kathy A. Low1, Monica  Fabian...</td>\n",
       "      <td>A27</td>\n",
       "      <td>CROSS-CORRELATION DYNAMICS OF FRONTO-PARIETAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Primary motor cortex  (M1) is critical for mot...</td>\n",
       "      <td>Mooshagian1,2,3, Aysha Keisler1,2, Trelawny Z...</td>\n",
       "      <td>A28</td>\n",
       "      <td>USING TRANSCRANIAL MAGNETIC STIMULATION TO AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Research  of the neural mechanisms underlying ...</td>\n",
       "      <td>Jayde Nail1, Hillary Schwarb1, Zain Sultan1, ...</td>\n",
       "      <td>A29</td>\n",
       "      <td>CORTICAL ACTIVATION CHANGES WITH PERFORMANCE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Anatomical brain structure does not fully pred...</td>\n",
       "      <td>elyn L Begany1,2, Emi M Nomura2,  Mark D'Espos...</td>\n",
       "      <td>A30</td>\n",
       "      <td>PREDICTING THE RESPONSE OF PATIENTS WITH BRAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Verbal and visuospatial working memory (WM) h...</td>\n",
       "      <td>Mary Rudner1, Eleni Orfanidou2,3, Cheryl  Cap...</td>\n",
       "      <td>C81</td>\n",
       "      <td>ACCESS TO LINGUISTIC STRUCTURE ENHANCES VISUO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>We investigated whether pattern classification...</td>\n",
       "      <td>IVIDUAL  Mossbridge1,  Marcia Grabowecky1, Sat...</td>\n",
       "      <td>C82</td>\n",
       "      <td>PATTERN CLASSIFICATION OF ERPS PREDICTS DIFFE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Training on working memory tasks can improve p...</td>\n",
       "      <td>TS OF WORKING MEMORY TRAINING  Bornali Kundu1,...</td>\n",
       "      <td>C83</td>\n",
       "      <td>VISUAL AND SPATIAL COMPONENTS OF VISUAL WORKI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Training on working memory tasks can improve p...</td>\n",
       "      <td>ali Kundu1, David W. Sutterer1, Bradley R. Pos...</td>\n",
       "      <td>C85</td>\n",
       "      <td>BEHAVIORAL AND EEG EFFECTS OF WORKING MEMORY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Oscillatory brain activity synchronized over a...</td>\n",
       "      <td>y A. Knaus1, Jodi Kamps2,  Richard Coppola2, D...</td>\n",
       "      <td>C86</td>\n",
       "      <td>GESTURAL EFFECTS ON LANGUAGE LEARNING IN YOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>While Turkish does  not have grammatical gende...</td>\n",
       "      <td>J. Seton1,2, Hanneke Loerts1,2,  Monika S. Sch...</td>\n",
       "      <td>C87</td>\n",
       "      <td>AUDITORY PROCESSING OF GRAMMATICAL GENDER: AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Stimulus-induced modulation of cortical rhythm...</td>\n",
       "      <td>via Ortiz-Mantilla1, Jarmo A Hämäläinen1,2, Ap...</td>\n",
       "      <td>C88</td>\n",
       "      <td>INFANTS SHOW INCREASED PHASE LOCKING OF OSCIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Recent event-related potential (ERP) evidence ...</td>\n",
       "      <td>1  1  2  1,2 1  Lori Astheimer , Monika Janus...</td>\n",
       "      <td>C89</td>\n",
       "      <td>ELECTROPHYSIOLOGICAL MEASURES OF ATTENTION DU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Bilinguals  and musicians have been shown to p...</td>\n",
       "      <td>Yunjo Lee1, Monika Janus2, Ellen  Bialystok1,...</td>\n",
       "      <td>C90</td>\n",
       "      <td>MUSIC AND LANGUAGE SHORT-TERM TRAINING REVEAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>A long-held assumption in language acquisition...</td>\n",
       "      <td>Christopher Conway1, Anne  Walk1, John Purdy2...</td>\n",
       "      <td>C91</td>\n",
       "      <td>ERP EVIDENCE FOR DIFFERENT SEQUENTIAL PATTERN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Within the domain of language, older adults de...</td>\n",
       "      <td>chele Diaz1, Micah Johnson1, C. Christine 1,  ...</td>\n",
       "      <td>C92</td>\n",
       "      <td>AGE-RELATED DIFFERENCES IN THE NEURAL BASES O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Developmental Dyslexia (DD) is characterized b...</td>\n",
       "      <td>, Elizabeth S.  Norton2,3, Abigail B. Cyr3, Sa...</td>\n",
       "      <td>C93</td>\n",
       "      <td>EXAMINING AT-RISK CLASSIFICATION FOR FUTURE R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Studies  suggest that choral singing or coordi...</td>\n",
       "      <td>Pascale Lidji1,2, Caroline Palmer1, Michele M...</td>\n",
       "      <td>C94</td>\n",
       "      <td>EFFECTS OF SYNCHRONIZATION, RHYTHM, AND MELOD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Developmental Dyslexia (DD) affects 5-17% of a...</td>\n",
       "      <td>Nadine Gaab1,2,3, Michael Figgucio1,4, Sarah ...</td>\n",
       "      <td>C95</td>\n",
       "      <td>BRAIN STRUCTURE IN PRESCHOOL IS ASSOCIATED WI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Acquired apraxia of speech (AOS) commonly co-o...</td>\n",
       "      <td>Karen Froud1, Reem Khamis-Dakwar2, Melissa Ra...</td>\n",
       "      <td>C96</td>\n",
       "      <td>MMN RESPONSES IN ACQUIRED APRAXIA OF SPEECH: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Numerous studies have  implicated under-recrui...</td>\n",
       "      <td>Brenda Hanna-Pladdy1, Rebecca Lepping2, Hyun ...</td>\n",
       "      <td>C97</td>\n",
       "      <td>MUSICAL EXPERIENCE BUFFERS AGE-RELATED DECLIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Previous research has shown that agency is a c...</td>\n",
       "      <td>auren Howard1, Amanda L. Woodward1, Tracy Rigg...</td>\n",
       "      <td>C98</td>\n",
       "      <td>THE EFFECTS OF AGENCY ON SEQUENTIAL MEMORY IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Verbal memory deficits attributed to late life...</td>\n",
       "      <td>Rebecca Charlton1, Melissa  Lamar1, Aifeng Zh...</td>\n",
       "      <td>C99</td>\n",
       "      <td>GRAY VERSUS WHITE MATTER DAMAGE ACROSS VERBAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Multiple brain systems support learning and me...</td>\n",
       "      <td>Karin Foerde1,  Erin Kendall Braun1, Daphna S...</td>\n",
       "      <td>C100</td>\n",
       "      <td>DOPAMINE MODULATION OF LEARNING WITH IMMEDIAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>In Hayes, Nadel and Ryan (2007) adults had 10%...</td>\n",
       "      <td>Jamie Edgin1, Spano Goffredina1, Kevin  Kawa1...</td>\n",
       "      <td>C101</td>\n",
       "      <td>THE ROLE OF SPATIAL CONTEXT IN OBJECT RECOGNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Metabolic syndrome affects  45% of Americans a...</td>\n",
       "      <td>Melissa  Lamar1, Rebecca Charlton1, Laura Kor...</td>\n",
       "      <td>C102</td>\n",
       "      <td>ASPECTS OF METABOLIC SYNDROME ACROSS THE LIFE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>In risky decision-making scenarios people are ...</td>\n",
       "      <td>. Losecaat Vermeer1,2, Maarten A.S. Boksem2,3,...</td>\n",
       "      <td>C103</td>\n",
       "      <td>NEURAL PREDICTORS OF RISKY BEHAVIOUR B. A.S. G.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Schizophrenia is associated with an abnormal d...</td>\n",
       "      <td>nsel1, Jenna Reinen1, Daphna  Shohamy1, Tor D....</td>\n",
       "      <td>C104</td>\n",
       "      <td>EFFECTS OF ATYPICAL ANTIPSYCHOTIC MEDICATION ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Previous neuroimaging  studies have shown that...</td>\n",
       "      <td>irgis1, Vlad B Papa2, Cary R Savage2, Keith W ...</td>\n",
       "      <td>C105</td>\n",
       "      <td>GENDER DIFFERENCES IN FINANCIAL RISK-TAKING B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Social decision-making is a complex process wi...</td>\n",
       "      <td>Filippo Rossi1, Luke Chang1, Ian Fasel1, Alan...</td>\n",
       "      <td>C106</td>\n",
       "      <td>MACHINE LEARNING OF SOCIAL DECISION-MAKING: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Deficits  in reward processing and in emotiona...</td>\n",
       "      <td>Christian Bellebaum1, Katja Brodmann1, Patriz...</td>\n",
       "      <td>C107</td>\n",
       "      <td>PROCESSING OF MONETARY FEEDBACK IN ACTIVE AND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Using a test-replication split-sample design w...</td>\n",
       "      <td>O'Dhaniel Mullette-gillman1,2, Edward McLaur...</td>\n",
       "      <td>C108</td>\n",
       "      <td>DAT1, DRD4, MAOA, STIN2, AND 5HTTLPR DO NOT A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Electronic  gambling games (EGMs) are extremel...</td>\n",
       "      <td>Scott  Oberg1, Matthew Tata1; 1University of ...</td>\n",
       "      <td>C109</td>\n",
       "      <td>LOADED REELS: NEAR-MISS OUTCOMES DURING GAMBL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Delay discounting (DD) portrays impulsive deci...</td>\n",
       "      <td>Uku  Vainik1,2, Andero Uusberg1, Jüri Allik1;...</td>\n",
       "      <td>C110</td>\n",
       "      <td>TEMPORAL CHARACTERISTICS OF DECISION-MAKING I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Goal-directed behavior is driven by reward des...</td>\n",
       "      <td>Ekaterina Dobryakova1, Elizabeth Tricomi1; 1R...</td>\n",
       "      <td>C111</td>\n",
       "      <td>MODULATION OF VENTRAL STRIATAL ACTIVITY BY SU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  abst  \\\n",
       "0    OBJEC-  TIVE: Auditory cues have been shown to...   \n",
       "1    Self-initiated sounds elicit an attenuated N1 ...   \n",
       "2    According to the object-based account of audit...   \n",
       "3    Selective  attention is often described as the...   \n",
       "4    Working memory (WM) is a temporary storage sys...   \n",
       "5    In a crowded sensory environment, organisms mu...   \n",
       "6    Brain imaging data were acquired from two subj...   \n",
       "7    Variability in cortical auditory-evoked respon...   \n",
       "8    Recent studies report activity in auditory cor...   \n",
       "9    When listening to music, we move in synchrony ...   \n",
       "10   The main goal of the study was to explore the ...   \n",
       "11   Memory retrieval of guilty self-actions is res...   \n",
       "12   Information encoded in relation to self throug...   \n",
       "13   Self-referential processing has been shown to ...   \n",
       "14   Studies (Alexander et. al 2005; Alexander et. ...   \n",
       "15   The current study represents a first attempt t...   \n",
       "16   One of the most Alpaugh2,3,  Brownoff3,  Singh...   \n",
       "17   Though several brain areas have been shown to ...   \n",
       "18   Self-knowledge is ipso facto the essential pie...   \n",
       "19   It has been established that insular cortex ma...   \n",
       "20   Self-knowledge is ipso facto the essential pie...   \n",
       "21   Previous studies have reported verbal fluency ...   \n",
       "22   Although much of our behavior is driven by rou...   \n",
       "23   Fronto-Parietal regions have been shown to rep...   \n",
       "24   The human brain is capable of performing numer...   \n",
       "25   Behavioural and neural evidence suggests that ...   \n",
       "26    Coordination between networks of brain region...   \n",
       "27   Primary motor cortex  (M1) is critical for mot...   \n",
       "28   Research  of the neural mechanisms underlying ...   \n",
       "29   Anatomical brain structure does not fully pred...   \n",
       "..                                                 ...   \n",
       "247   Verbal and visuospatial working memory (WM) h...   \n",
       "248  We investigated whether pattern classification...   \n",
       "249  Training on working memory tasks can improve p...   \n",
       "250  Training on working memory tasks can improve p...   \n",
       "251  Oscillatory brain activity synchronized over a...   \n",
       "252  While Turkish does  not have grammatical gende...   \n",
       "253  Stimulus-induced modulation of cortical rhythm...   \n",
       "254  Recent event-related potential (ERP) evidence ...   \n",
       "255  Bilinguals  and musicians have been shown to p...   \n",
       "256  A long-held assumption in language acquisition...   \n",
       "257  Within the domain of language, older adults de...   \n",
       "258  Developmental Dyslexia (DD) is characterized b...   \n",
       "259  Studies  suggest that choral singing or coordi...   \n",
       "260  Developmental Dyslexia (DD) affects 5-17% of a...   \n",
       "261  Acquired apraxia of speech (AOS) commonly co-o...   \n",
       "262  Numerous studies have  implicated under-recrui...   \n",
       "263  Previous research has shown that agency is a c...   \n",
       "264  Verbal memory deficits attributed to late life...   \n",
       "265  Multiple brain systems support learning and me...   \n",
       "266  In Hayes, Nadel and Ryan (2007) adults had 10%...   \n",
       "267  Metabolic syndrome affects  45% of Americans a...   \n",
       "268  In risky decision-making scenarios people are ...   \n",
       "269  Schizophrenia is associated with an abnormal d...   \n",
       "270  Previous neuroimaging  studies have shown that...   \n",
       "271  Social decision-making is a complex process wi...   \n",
       "272  Deficits  in reward processing and in emotiona...   \n",
       "273  Using a test-replication split-sample design w...   \n",
       "274  Electronic  gambling games (EGMs) are extremel...   \n",
       "275  Delay discounting (DD) portrays impulsive deci...   \n",
       "276  Goal-directed behavior is driven by reward des...   \n",
       "\n",
       "                                                  auth sect_abs  \\\n",
       "0    urtis1, Janna K. Comrie1, Anthony Colange1, Su...       A1   \n",
       "1     Jana Timm1, Iria SanMiguel1, Katja Saupe1,  E...       A2   \n",
       "2     Kristina  Backer1,2, Claude Alain1,2; 1Rotman...       A3   \n",
       "3    tian Pavlovic1, Karla D. Ponjavic-Conte1, Matt...       A4   \n",
       "4    STRACTORS Jessica  Tiffany Jantz1, Ezequiel Mo...       A5   \n",
       "5    lywy1, Ewan A. Macpherson1, Steven  G. Greenin...       A6   \n",
       "6     Kwaku Akrofi1, Jake  Carpenter-Thompson1, Fat...       A7   \n",
       "7      Dana Strait1, Nina Kraus1; 1Northwestern Uni...       A8   \n",
       "8     Cort Horton1, Michael D'Zmura1, Ramesh Sriniv...       A9   \n",
       "9     Shu-Jen Kung1,  Ovid Tzeng1,2, Daisy Hung1,3,...      A10   \n",
       "10    Szczepan  Grzybowski1, Miroslaw Wyczesany1; 1...      A11   \n",
       "11   to Miyauchi1,3, Motoaki Sugiura3, Yukihito Yom...      A12   \n",
       "12   ilip Collard1, David J. Turk1; 1  Psychology, ...      A13   \n",
       "13    Drucker1, Christine D. Wilson-  Mendenhall2, ...      A14   \n",
       "14    Joel  Alexander1, Ronald Alexander2; 1Western...      A15   \n",
       "15    Lauren 1  Kutcher1,  Steven  Brown1;  McMaste...      A16   \n",
       "16    Esther  Fujiwara1,2, Nick Anthony of Melanie ...      A17   \n",
       "17   .  Chavez1, Katherine E. Powers1, Todd F. Heat...      A18   \n",
       "18   ONSISTENT WITH EVOLUTIONARY UNDERSTANDING OF T...      A19   \n",
       "19   elder F. Araujo1,2,3, Jonas Kaplan1, Hanna Dam...      A20   \n",
       "20   ; 1Laboratoire de Sciences Cognitives et Psych...      A21   \n",
       "21    Ye Seul Shin1, Na Young Shin1,  Joon Hwan Jan...      A22   \n",
       "22   rlies  E. van Bochove1, Lise Van der Haegen1, ...      A23   \n",
       "23   saf  farooqui1, John Duncan1; 1MRC-Cognition &...      A24   \n",
       "24    Joseph Dubis1, Joshua Siegel1, Steven  Peters...      A25   \n",
       "25   rly S. Chiew1,  Renaldo Gacad1, Todd S. Braver...      A26   \n",
       "26   ne L. Baniqued1, Kathy A. Low1, Monica  Fabian...      A27   \n",
       "27    Mooshagian1,2,3, Aysha Keisler1,2, Trelawny Z...      A28   \n",
       "28    Jayde Nail1, Hillary Schwarb1, Zain Sultan1, ...      A29   \n",
       "29   elyn L Begany1,2, Emi M Nomura2,  Mark D'Espos...      A30   \n",
       "..                                                 ...      ...   \n",
       "247   Mary Rudner1, Eleni Orfanidou2,3, Cheryl  Cap...      C81   \n",
       "248  IVIDUAL  Mossbridge1,  Marcia Grabowecky1, Sat...      C82   \n",
       "249  TS OF WORKING MEMORY TRAINING  Bornali Kundu1,...      C83   \n",
       "250  ali Kundu1, David W. Sutterer1, Bradley R. Pos...      C85   \n",
       "251  y A. Knaus1, Jodi Kamps2,  Richard Coppola2, D...      C86   \n",
       "252  J. Seton1,2, Hanneke Loerts1,2,  Monika S. Sch...      C87   \n",
       "253  via Ortiz-Mantilla1, Jarmo A Hämäläinen1,2, Ap...      C88   \n",
       "254   1  1  2  1,2 1  Lori Astheimer , Monika Janus...      C89   \n",
       "255   Yunjo Lee1, Monika Janus2, Ellen  Bialystok1,...      C90   \n",
       "256   Christopher Conway1, Anne  Walk1, John Purdy2...      C91   \n",
       "257  chele Diaz1, Micah Johnson1, C. Christine 1,  ...      C92   \n",
       "258  , Elizabeth S.  Norton2,3, Abigail B. Cyr3, Sa...      C93   \n",
       "259   Pascale Lidji1,2, Caroline Palmer1, Michele M...      C94   \n",
       "260   Nadine Gaab1,2,3, Michael Figgucio1,4, Sarah ...      C95   \n",
       "261   Karen Froud1, Reem Khamis-Dakwar2, Melissa Ra...      C96   \n",
       "262   Brenda Hanna-Pladdy1, Rebecca Lepping2, Hyun ...      C97   \n",
       "263  auren Howard1, Amanda L. Woodward1, Tracy Rigg...      C98   \n",
       "264   Rebecca Charlton1, Melissa  Lamar1, Aifeng Zh...      C99   \n",
       "265   Karin Foerde1,  Erin Kendall Braun1, Daphna S...     C100   \n",
       "266   Jamie Edgin1, Spano Goffredina1, Kevin  Kawa1...     C101   \n",
       "267   Melissa  Lamar1, Rebecca Charlton1, Laura Kor...     C102   \n",
       "268  . Losecaat Vermeer1,2, Maarten A.S. Boksem2,3,...     C103   \n",
       "269  nsel1, Jenna Reinen1, Daphna  Shohamy1, Tor D....     C104   \n",
       "270  irgis1, Vlad B Papa2, Cary R Savage2, Keith W ...     C105   \n",
       "271   Filippo Rossi1, Luke Chang1, Ian Fasel1, Alan...     C106   \n",
       "272   Christian Bellebaum1, Katja Brodmann1, Patriz...     C107   \n",
       "273    O'Dhaniel Mullette-gillman1,2, Edward McLaur...     C108   \n",
       "274   Scott  Oberg1, Matthew Tata1; 1University of ...     C109   \n",
       "275   Uku  Vainik1,2, Andero Uusberg1, Jüri Allik1;...     C110   \n",
       "276   Ekaterina Dobryakova1, Elizabeth Tricomi1; 1R...     C111   \n",
       "\n",
       "                                                 title  \n",
       "0     EFFECTS OF AUDITORY CUES ON VISUAL ATTENTION:...  \n",
       "1     THE N1-SUPPRESSION EFFECT FOR SELF-INITIATED ...  \n",
       "2     RETRO-CUEING LISTENERS' ATTENTION TO SOUND OB...  \n",
       "3     NEURAL CORRELATES OF DISTRACTION IN AUDITORY ...  \n",
       "4     DISTURBING WORKING MEMORY: REHEARSAL, IMAGERY...  \n",
       "5     EFFECTS OF EMOTIONAL VALENCE ON THE ‘WHAT’ AN...  \n",
       "6     EFFECTS OF TINNITUS AND HEARING LOSS ON FUNCT...  \n",
       "7     IMPACTS OF SELECTIVE AUDITORY ATTENTION AND M...  \n",
       "8     SELECTIVE ATTENTION AND THE NEURAL REPRESENTA...  \n",
       "9     NEUROMAGNETIC CORRELATES OF DYNAMIC ALLOCATIO...  \n",
       "10        ERP STUDY OF SELF-REFERENCED MOOD ADJECTIVES  \n",
       "11    NEURAL REPRESENTATION OF GUILT IN EPISODIC ME...  \n",
       "12    OWNERSHIP AND ATTENTION: P300 MODULATION TO S...  \n",
       "13    NEURAL REPRESENTATIONS OF SELF AND OTHER: BEY...  \n",
       "14    P300 AMPLITUDE DIFFERENCES BETWEEN HETEROSEXU...  \n",
       "15                          THE NEUROSCIENCE OF ACTING  \n",
       "16          ERP CORRELATES OF THE SELF-POSITIVITY BIAS  \n",
       "17    STRUCTURAL CONNECTIVITY OF MEDIAL PREFRONTAL ...  \n",
       "18    NEURAL BASIS OF SELF-CONTINGENCY DETECTION IN...  \n",
       "19    INSULA CORTEX ACTIVITY DURING TWO SELF-RELATE...  \n",
       "20    FMRI STUDY OF SELF VS. OTHERS’ ATTRIBUTIONS O...  \n",
       "21    SWITCHING STRATEGY UNDERLIES VERBAL FLUENCY I...  \n",
       "22        BLINK PREDICTS ENHANCED COGNITIVE CONTROL E.  \n",
       "23    FRONTO-PARIETAL REPRESENTATION OF SEQUENTIAL ...  \n",
       "24    THE EFFECT OF RESOURCE-LIMITED AND DATA-LIMIT...  \n",
       "25    PUPILLOMETRY REVEALS CHANGES IN COGNITIVE CON...  \n",
       "26    CROSS-CORRELATION DYNAMICS OF FRONTO-PARIETAL...  \n",
       "27    USING TRANSCRANIAL MAGNETIC STIMULATION TO AS...  \n",
       "28    CORTICAL ACTIVATION CHANGES WITH PERFORMANCE ...  \n",
       "29    PREDICTING THE RESPONSE OF PATIENTS WITH BRAI...  \n",
       "..                                                 ...  \n",
       "247   ACCESS TO LINGUISTIC STRUCTURE ENHANCES VISUO...  \n",
       "248   PATTERN CLASSIFICATION OF ERPS PREDICTS DIFFE...  \n",
       "249   VISUAL AND SPATIAL COMPONENTS OF VISUAL WORKI...  \n",
       "250   BEHAVIORAL AND EEG EFFECTS OF WORKING MEMORY ...  \n",
       "251   GESTURAL EFFECTS ON LANGUAGE LEARNING IN YOUN...  \n",
       "252   AUDITORY PROCESSING OF GRAMMATICAL GENDER: AN...  \n",
       "253   INFANTS SHOW INCREASED PHASE LOCKING OF OSCIL...  \n",
       "254   ELECTROPHYSIOLOGICAL MEASURES OF ATTENTION DU...  \n",
       "255   MUSIC AND LANGUAGE SHORT-TERM TRAINING REVEAL...  \n",
       "256   ERP EVIDENCE FOR DIFFERENT SEQUENTIAL PATTERN...  \n",
       "257   AGE-RELATED DIFFERENCES IN THE NEURAL BASES O...  \n",
       "258   EXAMINING AT-RISK CLASSIFICATION FOR FUTURE R...  \n",
       "259   EFFECTS OF SYNCHRONIZATION, RHYTHM, AND MELOD...  \n",
       "260   BRAIN STRUCTURE IN PRESCHOOL IS ASSOCIATED WI...  \n",
       "261   MMN RESPONSES IN ACQUIRED APRAXIA OF SPEECH: ...  \n",
       "262   MUSICAL EXPERIENCE BUFFERS AGE-RELATED DECLIN...  \n",
       "263   THE EFFECTS OF AGENCY ON SEQUENTIAL MEMORY IN...  \n",
       "264   GRAY VERSUS WHITE MATTER DAMAGE ACROSS VERBAL...  \n",
       "265   DOPAMINE MODULATION OF LEARNING WITH IMMEDIAT...  \n",
       "266   THE ROLE OF SPATIAL CONTEXT IN OBJECT RECOGNI...  \n",
       "267   ASPECTS OF METABOLIC SYNDROME ACROSS THE LIFE...  \n",
       "268    NEURAL PREDICTORS OF RISKY BEHAVIOUR B. A.S. G.  \n",
       "269   EFFECTS OF ATYPICAL ANTIPSYCHOTIC MEDICATION ...  \n",
       "270   GENDER DIFFERENCES IN FINANCIAL RISK-TAKING B...  \n",
       "271   MACHINE LEARNING OF SOCIAL DECISION-MAKING: A...  \n",
       "272   PROCESSING OF MONETARY FEEDBACK IN ACTIVE AND...  \n",
       "273   DAT1, DRD4, MAOA, STIN2, AND 5HTTLPR DO NOT A...  \n",
       "274   LOADED REELS: NEAR-MISS OUTCOMES DURING GAMBL...  \n",
       "275   TEMPORAL CHARACTERISTICS OF DECISION-MAKING I...  \n",
       "276   MODULATION OF VENTRAL STRIATAL ACTIVITY BY SU...  \n",
       "\n",
       "[277 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "\n",
    "last_index = 0\n",
    "let_vec = ['A','B','C']\n",
    "\n",
    "for j in let_vec:\n",
    "    \n",
    "    print(j)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        try:\n",
    "            cur_section= j\n",
    "            cur_abs=i+1\n",
    "            abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "\n",
    "            for k in range(2,51):\n",
    "                try:\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "                    last_index = cur_section+'%i'%(cur_abs+1)\n",
    "                    #print('index found')\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    \n",
    "                    print('k = ',k)\n",
    "                    print(cur_section+'%i'%(cur_abs+k))\n",
    "                    abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+k))\n",
    "                    \n",
    "                    section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "                    #     print(section_abst)\n",
    "                    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "                    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "                    start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "                    start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "\n",
    "                    whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "                    title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "                    title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "                    title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "                    length_title_lst=' '.join(title_lst)\n",
    "                    remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "                    auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "\n",
    "\n",
    "                    sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "                    abst.append(whole_abs)\n",
    "                    title.append(remove_start_string)\n",
    "                    #auth.append(title_sect) old wrong way of getting author\n",
    "                    auth.append(auth_sect)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                except: \n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    pass\n",
    "\n",
    "                print(last_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_end_ind = abs_list.index((cur_section+1'%i'%(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "data_list = data.split('\\n')\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session B')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "#data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session B')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='B'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session C')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session D')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session C')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='C'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session D')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session E')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session D')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='D'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session E')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session F')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session E')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='E'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session F')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session G')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session F')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='F'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session G')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session H')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session G')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='G'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session H')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session I')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session H')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='H'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session I')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Topic Index')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session I')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='I'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        \n",
    "        \n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a datatable to see how the data fills the table which will help better understand the format i need to put the data into\n",
    "try_table=pd.DataFrame({'sect_abs':sect_abs,'abst':abst,'title':title,'auth':auth})\n",
    "try_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_table.to_csv(\"CNS_2012_SCRAPED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing another year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this cell specifically needs to be copied and pasted for every journal and needs to go first because all the rest of the cells use it to initialze abs_list\n",
    "sect_abs=[]\n",
    "abst=[]\n",
    "title=[]\n",
    "auth=[]\n",
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session A')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session B')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[6], 'r')# looks like this is the place where we call the specific year to parse\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "abs_start = [ind for ind, d in enumerate(data_list) if '\\x0cPoster Session A' in d][0]#tells you the ind where the first abstract is?\n",
    "abs_list = data_list[abs_start:]\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session A')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='A'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "data_list = data.split('\\n')\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session B')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session C')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[6], 'r')\n",
    "data = file.read()\n",
    "#data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session B')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='B'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "letter_start_ind = data_list.index('\\x0cPoster Session C')\n",
    "letter_end_ind = data_list.index('\\x0cPoster Session D')\n",
    "a_b_range= range(letter_start_ind,letter_end_ind)\n",
    "a_b_range=list(a_b_range)\n",
    "file = open(data_folder+CNS_files[5], 'r')\n",
    "data = file.read()\n",
    "data_list = data.split('\\n')\n",
    "poster_beg_ind = data_list.index('\\x0cPoster Session C')\n",
    "#while cur_section = 'A':#dont know how this cur_section string being A will work. thinking \n",
    "    #better idea being from poster_beg_ind = data_list.index('\\x0cPoster Session A') \n",
    "    #to poster_beg_ind = data_list.index('\\x0cPoster Session B') make this a range\n",
    "#['A' 'B']\n",
    "#for cur_section in \n",
    "for i in range(len(a_b_range)):\n",
    "    try:\n",
    "        cur_section='C'\n",
    "        cur_abs=i+1\n",
    "        abs_beg_ind = abs_list.index(cur_section+'%i'%cur_abs)\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+1))\n",
    "\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract \n",
    "    #     print(section_abst)\n",
    "    #     print(cur_section+'%i'%(cur_abs+1))\n",
    "    #     print(i, abs_beg_ind, abs_end_ind)\n",
    "        start_abst=section_abst.index(' — ')#index with in the section where we first see this character - which denotes start of abs\n",
    "        start_string=cur_section+'%i'%cur_abs #the F4 like number at the beg of each title that isnt needed\n",
    "        \n",
    "        whole_abs=section_abst[start_abst+3:len(section_abst)]#the abstract separated from the title and author\n",
    "        title_sect=section_abst[0:start_abst]#the title and author combined\n",
    "        title_auth_lst=title_sect.split(' ')#splits them up into list items so that the lamdas will work? have not tried to run without this\n",
    "        title_lst=[word for word in title_auth_lst if word.isupper()]#takes only all uppercase words\n",
    "        length_title_lst=' '.join(title_lst)\n",
    "        remove_start_string=length_title_lst.replace(start_string,\"\")\n",
    "        auth_sect=section_abst[len(length_title_lst):start_abst]\n",
    "        \n",
    "        \n",
    "\n",
    "        sect_abs.append(cur_section+'%i'%cur_abs)\n",
    "        abst.append(whole_abs)\n",
    "        title.append(remove_start_string)\n",
    "        #auth.append(title_sect) old wrong way of getting author\n",
    "        auth.append(auth_sect)\n",
    "    except :\n",
    "        abs_end_ind = abs_list.index(cur_section+'%i'%(cur_abs+2)) #works!!\n",
    "        section_abst=' '.join(abs_list[abs_beg_ind:abs_end_ind])#entire section including title author and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
